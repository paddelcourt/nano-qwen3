<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qwen3 Transformer: Interactive Learning Tutorial</title>
    <style>
        * {
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Inter', Roboto, sans-serif;
            margin: 0;
            padding: 0;
            background: #0a0a0a;
            color: #e0e0e0;
            line-height: 1.6;
            font-size: 16px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 24px;
        }
        
        h1, h2, h3, h4 {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        h1 {
            font-size: 32px;
            font-weight: 700;
            margin: 0 0 8px 0;
            line-height: 1.2;
        }
        
        h2 {
            font-size: 24px;
            font-weight: 600;
            margin: 32px 0 16px 0;
            line-height: 1.3;
        }
        
        h3 {
            font-size: 20px;
            font-weight: 600;
            margin: 24px 0 12px 0;
        }
        
        h4 {
            font-size: 16px;
            font-weight: 600;
            margin: 16px 0 8px 0;
        }
        
        .intro {
            font-size: 18px;
            color: #a0a0a0;
            margin: 0 0 40px 0;
            line-height: 1.5;
        }
        
        .section {
            margin-bottom: 24px;
        }
        
        .challenge-box {
            background: #151515;
            border: 2px solid #667eea;
            border-radius: 8px;
            margin: 16px 0;
            overflow: hidden;
        }
        
        .challenge-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 16px 20px;
            cursor: pointer;
            transition: background-color 0.2s ease;
        }
        
        .challenge-header:hover {
            background: rgba(102, 126, 234, 0.1);
        }
        
        .challenge-title {
            font-size: 16px;
            font-weight: 600;
            color: #667eea;
            margin: 0;
        }
        
        .difficulty {
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .difficulty.easy {
            background: rgba(102, 234, 126, 0.2);
            color: #66ea7e;
        }
        
        .difficulty.medium {
            background: rgba(234, 166, 102, 0.2);
            color: #eaa666;
        }
        
        .difficulty.hard {
            background: rgba(234, 102, 102, 0.2);
            color: #ea6666;
        }
        
        .hint-section {
            margin: 20px 0;
        }
        
        .hint-box {
            background: rgba(102, 126, 234, 0.1);
            border-left: 4px solid #667eea;
            border-radius: 0 6px 6px 0;
            padding: 16px 20px;
            margin: 12px 0;
            display: none;
        }
        
        .hint-box.visible {
            display: block;
            animation: fadeIn 0.5s ease-out;
        }
        
        .hint-button {
            background: #2a2a2a;
            color: #667eea;
            border: 1px solid #667eea;
            padding: 8px 12px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 14px;
            margin-right: 8px;
            transition: all 0.2s ease;
            font-weight: 500;
        }
        
        .hint-button:hover {
            background: #667eea;
            color: white;
        }
        
        .starter-code {
            background: #1e1e1e;
            border: 1px solid #2a2a2a;
            border-radius: 6px;
            margin: 16px 0;
            overflow: hidden;
        }
        
        .starter-code pre {
            margin: 0;
            padding: 16px;
            overflow-x: auto;
            font-family: 'SF Mono', Monaco, Consolas, 'Liberation Mono', 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.4;
            color: #e0e0e0;
        }
        
        .solution-section {
            margin-top: 24px;
        }
        
        .solution-toggle {
            background: #764ba2;
            color: white;
            border: none;
            padding: 10px 16px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .solution-toggle:hover {
            background: #8b5de5;
            transform: translateY(-1px);
        }
        
        .solution-content {
            display: none;
            margin-top: 20px;
        }
        
        .solution-content.visible {
            display: block;
            animation: fadeIn 0.5s ease-out;
        }
        
        .code-block {
            background: #1e1e1e;
            border: 1px solid #2a2a2a;
            border-radius: 6px;
            padding: 16px;
            margin: 16px 0;
            overflow-x: auto;
            position: relative;
            font-family: 'SF Mono', Monaco, Consolas, 'Liberation Mono', 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.4;
        }
        
        .code-block pre {
            margin: 0;
            color: #e0e0e0;
            font-family: inherit;
            font-size: inherit;
            line-height: inherit;
        }
        
        .copy-button {
            position: absolute;
            top: 8px;
            right: 8px;
            background: #667eea;
            color: white;
            border: none;
            padding: 6px 10px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
            transition: all 0.2s ease;
            font-weight: 500;
        }
        
        .copy-button:hover {
            background: #764ba2;
            transform: translateY(-1px);
        }
        
        .concept-card {
            background: #1a1a1a;
            border: 1px solid #2a2a2a;
            border-radius: 6px;
            padding: 20px;
            margin: 16px 0;
        }
        
        .visualization-container {
            background: #1a1a1a;
            border-radius: 6px;
            padding: 20px;
            margin: 16px 0;
            border: 1px solid #2a2a2a;
            text-align: center;
        }
        
        .progress-tracker {
            background: #151515;
            border-radius: 6px;
            padding: 16px;
            margin-bottom: 24px;
            border: 1px solid #2a2a2a;
        }
        
        .progress-item {
            display: flex;
            align-items: center;
            gap: 12px;
            margin: 12px 0;
        }
        
        .progress-checkbox {
            width: 24px;
            height: 24px;
            border: 2px solid #667eea;
            border-radius: 50%;
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
        }
        
        .progress-checkbox.checked {
            background: #667eea;
        }
        
        .progress-checkbox.checked::after {
            content: '✓';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-weight: bold;
        }
        
        .learning-tip {
            background: rgba(102, 234, 126, 0.1);
            border-left: 3px solid #66ea7e;
            padding: 16px 20px;
            margin: 16px 0;
            border-radius: 0 6px 6px 0;
        }
        
        .learning-tip strong {
            color: #66ea7e;
        }
        
        /* Syntax highlighting */
        .keyword { color: #c678dd; font-weight: 500; }
        .string { color: #98c379; }
        .number { color: #d19a66; }
        .comment { color: #5c6370; font-style: italic; }
        .function { color: #61afef; }
        .class-name { color: #e06c75; font-weight: 500; }
        .decorator { color: #e5c07b; }
        .todo { background: #e06c75; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; }
        
        /* Animation */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        /* SVG styles */
        .arch-component {
            fill: #1a1a1a;
            stroke: #667eea;
            stroke-width: 2;
            transition: all 0.3s ease;
        }
        
        .arch-component:hover {
            fill: #2a2a2a;
            stroke: #764ba2;
            stroke-width: 3;
        }
        
        .arch-text {
            fill: #e0e0e0;
            font-size: 14px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            pointer-events: none;
        }
        
        .flow-arrow {
            stroke: #667eea;
            stroke-width: 2;
            fill: none;
            marker-end: url(#arrowhead);
        }
        
        /* Collapsible sections */
        .section-header {
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 0;
            padding: 12px 0;
            border-bottom: 1px solid #2a2a2a;
        }
        
        .section-header:hover {
            background: rgba(102, 126, 234, 0.1);
            margin: 0 -16px;
            padding: 12px 16px;
            border-radius: 6px;
        }
        
        .section-content {
            max-height: 10000px;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
            padding-top: 16px;
        }
        
        .section-content.collapsed {
            max-height: 0;
            padding-top: 0;
        }
        
        .collapse-icon {
            font-size: 14px;
            transition: transform 0.2s ease;
            color: #667eea;
            font-weight: 600;
        }
        
        .collapse-icon.collapsed {
            transform: rotate(-90deg);
        }
        
        .challenge-content {
            max-height: 10000px;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
            padding: 20px;
        }
        
        .challenge-content.collapsed {
            max-height: 0;
            padding: 0 20px;
        }
    </style>
    <script>
        // Toggle collapsible sections
        function toggleSection(sectionId) {
            const content = document.getElementById(sectionId + '-content');
            const icon = document.getElementById(sectionId + '-icon');
            
            content.classList.toggle('collapsed');
            icon.classList.toggle('collapsed');
        }
        
        // Toggle collapsible challenges
        function toggleChallenge(challengeId) {
            const content = document.getElementById(challengeId + '-content');
            const icon = document.getElementById(challengeId + '-icon');
            
            content.classList.toggle('collapsed');
            icon.classList.toggle('collapsed');
        }
        
        // Auto-make sections collapsible on page load
        document.addEventListener('DOMContentLoaded', function() {
            // Make all h2 headers clickable and collapsible
            const h2Elements = document.querySelectorAll('.section h2');
            h2Elements.forEach((h2, index) => {
                const section = h2.closest('.section');
                if (!section) return;
                
                // Skip if already has collapsible structure
                if (section.querySelector('.section-header')) return;
                
                const sectionId = 'section-' + index;
                
                // Wrap h2 in header div
                const header = document.createElement('div');
                header.className = 'section-header';
                header.onclick = () => toggleSection(sectionId);
                
                const icon = document.createElement('span');
                icon.className = 'collapse-icon';
                icon.id = sectionId + '-icon';
                icon.textContent = '▼';
                
                // Replace h2 with header structure
                h2.parentNode.insertBefore(header, h2);
                header.appendChild(h2);
                header.appendChild(icon);
                
                // Wrap rest of section content
                const content = document.createElement('div');
                content.className = 'section-content';
                content.id = sectionId + '-content';
                
                let nextSibling = header.nextSibling;
                while (nextSibling) {
                    const currentSibling = nextSibling;
                    nextSibling = nextSibling.nextSibling;
                    content.appendChild(currentSibling);
                }
                
                section.appendChild(content);
            });
            
            // Make all challenge headers clickable and collapsible
            const challengeHeaders = document.querySelectorAll('.challenge-header');
            challengeHeaders.forEach((header, index) => {
                // Skip if already has onclick
                if (header.onclick) return;
                
                const challengeBox = header.closest('.challenge-box');
                if (!challengeBox) return;
                
                const challengeId = 'challenge-' + index;
                
                // Add onclick to header
                header.onclick = () => toggleChallenge(challengeId);
                header.style.cursor = 'pointer';
                
                // Add collapse icon if not exists
                if (!header.querySelector('.collapse-icon')) {
                    const icon = document.createElement('span');
                    icon.className = 'collapse-icon';
                    icon.id = challengeId + '-icon';
                    icon.textContent = '▼';
                    
                    // Add to existing difficulty container or create new one
                    const difficulty = header.querySelector('.difficulty');
                    if (difficulty && difficulty.parentNode) {
                        difficulty.parentNode.appendChild(icon);
                    } else {
                        header.appendChild(icon);
                    }
                }
                
                // Wrap content after header
                const content = document.createElement('div');
                content.className = 'challenge-content';
                content.id = challengeId + '-content';
                
                let nextSibling = header.nextSibling;
                while (nextSibling) {
                    const currentSibling = nextSibling;
                    nextSibling = nextSibling.nextSibling;
                    content.appendChild(currentSibling);
                }
                
                challengeBox.appendChild(content);
            });
            
            // Start with most sections collapsed by default to create minimal view
            setTimeout(() => {
                const allContents = document.querySelectorAll('.section-content');
                const allIcons = document.querySelectorAll('.section-header .collapse-icon');
                
                // Collapse all sections except the first one
                allContents.forEach((content, index) => {
                    if (index > 0) { // Keep first section open
                        content.classList.add('collapsed');
                    }
                });
                
                allIcons.forEach((icon, index) => {
                    if (index > 0) { // Keep first section open
                        icon.classList.add('collapsed');
                    }
                });
                
                // Also collapse all challenges by default
                const allChallengeContents = document.querySelectorAll('.challenge-content');
                const allChallengeIcons = document.querySelectorAll('.challenge-header .collapse-icon');
                
                allChallengeContents.forEach(content => {
                    content.classList.add('collapsed');
                });
                
                allChallengeIcons.forEach(icon => {
                    icon.classList.add('collapsed');
                });
            }, 100);
        });
        
        // Expand/Collapse all sections
        function toggleAllSections(expand = true) {
            const allContents = document.querySelectorAll('.section-content, .challenge-content');
            const allIcons = document.querySelectorAll('.collapse-icon');
            
            allContents.forEach(content => {
                if (expand) {
                    content.classList.remove('collapsed');
                } else {
                    content.classList.add('collapsed');
                }
            });
            
            allIcons.forEach(icon => {
                if (expand) {
                    icon.classList.remove('collapsed');
                } else {
                    icon.classList.add('collapsed');
                }
            });
        }
        
        // Toggle progress checkboxes
        function toggleCheck(id) {
            const checkbox = document.getElementById(id);
            checkbox.classList.toggle('checked');
            
            // Save progress to localStorage
            const progress = {};
            document.querySelectorAll('.progress-checkbox').forEach(cb => {
                progress[cb.id] = cb.classList.contains('checked');
            });
            localStorage.setItem('qwen3-progress', JSON.stringify(progress));
        }
        
        // Load saved progress
        window.addEventListener('load', () => {
            const savedProgress = localStorage.getItem('qwen3-progress');
            if (savedProgress) {
                const progress = JSON.parse(savedProgress);
                Object.keys(progress).forEach(id => {
                    if (progress[id]) {
                        document.getElementById(id)?.classList.add('checked');
                    }
                });
            }
        });
        
        // Show hints
        function showHint(hintId) {
            const hint = document.getElementById(hintId);
            hint.classList.toggle('visible');
        }
        
        // Toggle solution
        function toggleSolution(solutionId) {
            const solution = document.getElementById(solutionId);
            solution.classList.toggle('visible');
            
            // Update button text
            const button = event.target.closest('.solution-toggle');
            const isVisible = solution.classList.contains('visible');
            button.innerHTML = isVisible 
                ? '<span>🔒</span><span>Hide Solution</span>'
                : '<span>🔓</span><span>Show Solution</span>';
        }
        
        // Copy code
        function copyCode(codeId) {
            const codeElement = document.getElementById(codeId);
            const textToCopy = codeElement.textContent || codeElement.innerText;
            
            navigator.clipboard.writeText(textToCopy).then(() => {
                // Change button text temporarily
                const button = event.target;
                const originalText = button.textContent;
                button.textContent = 'Copied!';
                button.style.background = '#10b981';
                
                setTimeout(() => {
                    button.textContent = originalText;
                    button.style.background = '#667eea';
                }, 2000);
            }).catch(err => {
                console.error('Failed to copy text: ', err);
            });
        }
    </script>
</head>
<body>
    <div class="container">
        <h1>🎯 Qwen3 Transformer: Interactive Learning Tutorial</h1>
        <p class="intro">
            Build your own Qwen3 transformer from scratch! Based on the official technical report,
            this tutorial includes coding challenges, hints, and hidden solutions. Perfect for learning 
            how modern transformers work, especially the innovations that make Qwen3 special.
        </p>
        
        <!-- Section Controls -->
        <div style="text-align: center; margin: 24px 0; padding: 16px 0; border-bottom: 1px solid #2a2a2a;">
            <button onclick="toggleAllSections(true)" style="background: #667eea; color: white; border: none; padding: 8px 16px; border-radius: 6px; margin: 0 6px; cursor: pointer; font-size: 14px; font-weight: 500;">
                📖 Expand All
            </button>
            <button onclick="toggleAllSections(false)" style="background: transparent; color: #a0a0a0; border: 1px solid #2a2a2a; padding: 8px 16px; border-radius: 6px; margin: 0 6px; cursor: pointer; font-size: 14px; font-weight: 500;">
                📚 Collapse All
            </button>
        </div>
        
        <!-- Getting Started Section -->
        <div class="section">
            <h2>🚀 Getting Started</h2>
            
            <div class="concept-card">
                <h3>📋 What You'll Build</h3>
                <p>By the end of this tutorial, you'll have a complete Qwen3 model that can:</p>
                <ul>
                    <li><strong>Generate Text:</strong> Predict next tokens like "Once upon a time there was a..."</li>
                    <li><strong>Use GQA:</strong> Efficient attention mechanism from the latest research</li>
                    <li><strong>Handle Positions:</strong> Understand word order with RoPE</li>
                    <li><strong>Train Fast:</strong> Stable training with QK normalization</li>
                    <li><strong>Scale Up:</strong> Architecture that works from 2M to 235B parameters</li>
                </ul>
            </div>
            
            <div class="learning-tip">
                <strong>🎯 Perfect For:</strong>
                <ul>
                    <li>ML students wanting to understand transformers deeply</li>
                    <li>Researchers implementing new attention mechanisms</li>
                    <li>Engineers building custom language models</li>
                    <li>Anyone curious about how ChatGPT-style models work!</li>
                </ul>
            </div>
            
            <div class="concept-card">
                <h3>⚡ Quick Setup (5 minutes)</h3>
                <div class="code-block">
                    <button class="copy-button" onclick="copyCode('setup-code')">Copy</button>
                    <pre id="setup-code"># 1. Install dependencies
pip install torch numpy tiktoken tqdm requests

# 2. Create a new Python file
touch qwen3_model.py

# 3. Start with the first challenge below!
# Copy each solution into your file as you go</pre>
                </div>
                <p><strong>💡 Tip:</strong> Work through each challenge in order. Each builds on the previous one!</p>
            </div>
            
            <div class="visualization-container">
                <h3>🗺️ Tutorial Roadmap</h3>
                <svg width="100%" height="150" viewBox="0 0 700 150">
                    <!-- Step boxes -->
                    <rect x="20" y="60" width="80" height="30" class="arch-component" />
                    <text x="60" y="80" text-anchor="middle" class="arch-text" font-size="12">Config</text>
                    
                    <rect x="130" y="60" width="80" height="30" class="arch-component" />
                    <text x="170" y="80" text-anchor="middle" class="arch-text" font-size="12">RoPE</text>
                    
                    <rect x="240" y="60" width="80" height="30" class="arch-component" />
                    <text x="280" y="80" text-anchor="middle" class="arch-text" font-size="12">GQA</text>
                    
                    <rect x="350" y="60" width="80" height="30" class="arch-component" />
                    <text x="390" y="80" text-anchor="middle" class="arch-text" font-size="12">FFN</text>
                    
                    <rect x="460" y="60" width="80" height="30" class="arch-component" />
                    <text x="500" y="80" text-anchor="middle" class="arch-text" font-size="12">Layer</text>
                    
                    <rect x="570" y="60" width="80" height="30" class="arch-component" />
                    <text x="610" y="80" text-anchor="middle" class="arch-text" font-size="12">Model</text>
                    
                    <!-- Arrows -->
                    <line x1="100" y1="75" x2="125" y2="75" class="flow-arrow" />
                    <line x1="210" y1="75" x2="235" y2="75" class="flow-arrow" />
                    <line x1="320" y1="75" x2="345" y2="75" class="flow-arrow" />
                    <line x1="430" y1="75" x2="455" y2="75" class="flow-arrow" />
                    <line x1="540" y1="75" x2="565" y2="75" class="flow-arrow" />
                    
                    <!-- Time estimates -->
                    <text x="60" y="110" text-anchor="middle" class="arch-text" font-size="10">5 min</text>
                    <text x="170" y="110" text-anchor="middle" class="arch-text" font-size="10">15 min</text>
                    <text x="280" y="110" text-anchor="middle" class="arch-text" font-size="10">25 min</text>
                    <text x="390" y="110" text-anchor="middle" class="arch-text" font-size="10">10 min</text>
                    <text x="500" y="110" text-anchor="middle" class="arch-text" font-size="10">10 min</text>
                    <text x="610" y="110" text-anchor="middle" class="arch-text" font-size="10">15 min</text>
                    
                    <text x="350" y="130" text-anchor="middle" class="arch-text" font-size="12">Total: ~90 minutes</text>
                </svg>
            </div>
        </div>
        
        <!-- Progress Tracker -->
        <div class="progress-tracker">
            <h3>📊 Your Progress</h3>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-config" onclick="toggleCheck('check-config')"></div>
                <span>Configuration & Setup</span>
            </div>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-rope" onclick="toggleCheck('check-rope')"></div>
                <span>Rotary Position Embeddings (RoPE)</span>
            </div>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-attention" onclick="toggleCheck('check-attention')"></div>
                <span>Grouped Query Attention (GQA)</span>
            </div>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-ffn" onclick="toggleCheck('check-ffn')"></div>
                <span>Feed-Forward Network</span>
            </div>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-layer" onclick="toggleCheck('check-layer')"></div>
                <span>Transformer Layer</span>
            </div>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-model" onclick="toggleCheck('check-model')"></div>
                <span>Complete Model</span>
            </div>
            <div class="progress-item">
                <div class="progress-checkbox" id="check-training" onclick="toggleCheck('check-training')"></div>
                <span>Training on TinyStories</span>
            </div>
        </div>
        
        <!-- Prerequisites Section -->
        <div class="section">
            <h2>🎓 Prerequisites: What You Need to Know</h2>
            
            <div class="concept-card">
                <h3>📚 Essential Background</h3>
                <p>Before diving in, make sure you understand these concepts:</p>
                <ul>
                    <li><strong>Python & PyTorch:</strong> Basic familiarity with neural networks and PyTorch modules</li>
                    <li><strong>Transformers:</strong> Understanding of attention, embeddings, and layer normalization</li>
                    <li><strong>Matrix Operations:</strong> Basic linear algebra (dot products, matrix multiplication)</li>
                    <li><strong>Deep Learning:</strong> Forward/backward pass, gradients, loss functions</li>
                </ul>
                <p><strong>Don't worry if you're rusty!</strong> This tutorial explains everything step-by-step.</p>
            </div>
        </div>

        <!-- PyTorch Fundamentals Section -->
        <div class="section">
            <h2>🔥 PyTorch Fundamentals for Beginners</h2>
            
            <div class="concept-card">
                <h3>📦 What is PyTorch?</h3>
                <p>PyTorch is a deep learning framework that makes building neural networks easy:</p>
                <ul>
                    <li><strong>Tensors:</strong> Like NumPy arrays but can run on GPU</li>
                    <li><strong>Automatic Differentiation:</strong> Automatically computes gradients</li>
                    <li><strong>Neural Network Modules:</strong> Pre-built components like Linear layers</li>
                    <li><strong>GPU Support:</strong> Accelerated computation for training</li>
                </ul>
            </div>
            
            <div class="learning-tip">
                <strong>🤔 Think of PyTorch Like LEGO:</strong>
                <ul>
                    <li><strong>Tensors</strong> = Individual LEGO pieces (data)</li>
                    <li><strong>Modules</strong> = Pre-built LEGO sets (nn.Linear, nn.RMSNorm)</li>
                    <li><strong>Models</strong> = Complete LEGO creations (transformer)</li>
                    <li><strong>Training</strong> = Following the instruction manual</li>
                </ul>
            </div>
            
            <div class="concept-card">
                <h3>🔢 Essential Tensor Operations</h3>
                <p>Here are the key tensor operations you'll see throughout this tutorial:</p>
                
                <div class="code-block">
                    <button class="copy-button" onclick="copyCode('pytorch-basics-code')">Copy</button>
                    <pre id="pytorch-basics-code"># Creating tensors
x = torch.randn(2, 3, 4)  # Random tensor: 2 batches, 3 sequence, 4 features
print(f"Shape: {x.shape}")  # Output: torch.Size([2, 3, 4])

# Key operations you'll see:
y = x.view(2, 3, 4)          # Reshape (same data, new shape)
z = x.transpose(1, 2)        # Swap dimensions: (2,3,4) → (2,4,3)
w = x.unsqueeze(0)           # Add dimension: (2,3,4) → (1,2,3,4)
v = x.squeeze()              # Remove size-1 dimensions

# Mathematical operations
mean = x.mean(dim=-1)        # Average along last dimension
norm = x.pow(2).mean(-1)     # Square, then mean (used in RMSNorm)
scaled = x * 0.5             # Element-wise multiplication

# Matrix operations (crucial for attention!)
a = torch.randn(2, 3, 4)
b = torch.randn(2, 4, 5)
result = torch.matmul(a, b)  # Matrix multiply: (2,3,4) × (2,4,5) = (2,3,5)

print("🎯 These operations are the building blocks of transformers!")</pre>
                </div>
            </div>
            
            <div class="concept-card">
                <h3>🧠 Understanding Tensor Shapes</h3>
                <p>Shape understanding is crucial for transformers. Here's how to think about them:</p>
                
                <div style="background: #0a0a0a; padding: 15px; border-radius: 8px; margin: 10px 0;">
                    <strong>Transformer Tensor Shapes:</strong><br>
                    • <strong>[batch_size, seq_len, hidden_size]</strong> ← Most common<br>
                    • <strong>[batch_size, num_heads, seq_len, head_dim]</strong> ← Multi-head attention<br>
                    • <strong>[batch_size, seq_len, vocab_size]</strong> ← Output logits
                </div>
                
                <div class="learning-tip">
                    <strong>🔍 Shape Debugging Tip:</strong>
                    <p>Always print tensor shapes when debugging!</p>
                    <pre style="font-size: 12px;">print(f"x.shape: {x.shape}")  # Your best friend for debugging</pre>
                </div>
            </div>
            
            <div class="concept-card">
                <h3>🏗️ PyTorch Neural Network Basics</h3>
                <p>Understanding nn.Module - the foundation of all PyTorch models:</p>
                
                <div class="code-block">
                    <button class="copy-button" onclick="copyCode('pytorch-module-code')">Copy</button>
                    <pre id="pytorch-module-code">import torch
import torch.nn as nn

# Every neural network component inherits from nn.Module
class SimpleLayer(nn.Module):
    def __init__(self, input_size, output_size):
        super().__init__()  # Always call this first!
        
        # Define components in __init__
        self.linear = nn.Linear(input_size, output_size)
        self.activation = nn.ReLU()
        
    def forward(self, x):
        # Define the computation in forward
        x = self.linear(x)
        x = self.activation(x)
        return x

# Usage
layer = SimpleLayer(10, 5)
input_tensor = torch.randn(3, 10)  # batch_size=3, features=10
output = layer(input_tensor)       # This calls forward() automatically
print(f"Input: {input_tensor.shape}, Output: {output.shape}")

# Key concepts:
# 1. __init__: Define what your layer contains
# 2. forward: Define what your layer does
# 3. nn.Parameter: Learnable weights (automatically handled by nn.Linear)
# 4. Call layer(x), not layer.forward(x)</pre>
                </div>
            </div>
            
            <div class="concept-card">
                <h3>🎯 Common PyTorch Patterns in Transformers</h3>
                
                <div style="margin: 15px 0;">
                    <strong>1. Reshape for Multi-Head Attention:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 12px;"># From: [batch, seq, hidden_size] 
# To: [batch, num_heads, seq, head_dim]
x = x.view(batch, seq, num_heads, head_dim).transpose(1, 2)</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>2. Matrix Multiplication for Attention:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 12px;"># Attention scores: Q × K^T
attention_scores = torch.matmul(queries, keys.transpose(-2, -1))</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>3. Softmax for Attention Weights:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 12px;"># Convert scores to probabilities
attention_weights = F.softmax(attention_scores, dim=-1)</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>4. Masked Fill for Causal Attention:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 12px;"># Hide future tokens
mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()
scores = scores.masked_fill(mask, float('-inf'))</pre>
                    </div>
                </div>
            </div>
        </div>

        <!-- Architecture Overview -->
        <div class="section">
            <h2>🏗️ Qwen3 Architecture Overview</h2>
            
            <div class="visualization-container">
                <h3>🔍 How Qwen3 Works (High Level)</h3>
                <svg width="100%" height="400" viewBox="0 0 800 400">
                    <!-- Define arrow marker -->
                    <defs>
                        <marker id="arrowhead" markerWidth="10" markerHeight="7" 
                                refX="10" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="#667eea" />
                        </marker>
                    </defs>
                    
                    <!-- Input -->
                    <rect x="50" y="350" width="100" height="30" class="arch-component" />
                    <text x="100" y="370" text-anchor="middle" class="arch-text">Input Tokens</text>
                    
                    <!-- Embedding -->
                    <rect x="200" y="320" width="120" height="60" class="arch-component" />
                    <text x="260" y="345" text-anchor="middle" class="arch-text">Token</text>
                    <text x="260" y="360" text-anchor="middle" class="arch-text">Embeddings</text>
                    
                    <!-- Transformer Layers -->
                    <rect x="370" y="250" width="140" height="140" class="arch-component" />
                    <text x="440" y="275" text-anchor="middle" class="arch-text">6x Transformer</text>
                    <text x="440" y="290" text-anchor="middle" class="arch-text">Layers</text>
                    
                    <!-- Attention detail -->
                    <rect x="380" y="300" width="120" height="25" fill="#2a2a2a" stroke="#764ba2" />
                    <text x="440" y="317" text-anchor="middle" class="arch-text" font-size="12">GQA + RoPE</text>
                    
                    <!-- FFN detail -->
                    <rect x="380" y="330" width="120" height="25" fill="#2a2a2a" stroke="#764ba2" />
                    <text x="440" y="347" text-anchor="middle" class="arch-text" font-size="12">SwiGLU FFN</text>
                    
                    <!-- Output -->
                    <rect x="560" y="320" width="120" height="60" class="arch-component" />
                    <text x="620" y="345" text-anchor="middle" class="arch-text">Language</text>
                    <text x="620" y="360" text-anchor="middle" class="arch-text">Model Head</text>
                    
                    <!-- Final output -->
                    <rect x="720" y="350" width="60" height="30" class="arch-component" />
                    <text x="750" y="370" text-anchor="middle" class="arch-text">Logits</text>
                    
                    <!-- Arrows -->
                    <line x1="150" y1="365" x2="190" y2="355" class="flow-arrow" />
                    <line x1="320" y1="350" x2="360" y2="330" class="flow-arrow" />
                    <line x1="510" y1="320" x2="550" y2="350" class="flow-arrow" />
                    <line x1="680" y1="350" x2="710" y2="365" class="flow-arrow" />
                </svg>
                
                <p style="margin-top: 20px;">
                    <strong>🔄 Data Flow:</strong> Text → Tokens → Embeddings → 6 Transformer Layers → Language Model Head → Next Token Prediction
                </p>
            </div>
            
            <div class="concept-card">
                <h3>🧠 What Makes Qwen3 Special?</h3>
                <p>According to the technical report, Qwen3 has several key innovations:</p>
                <ol>
                    <li><strong>Grouped Query Attention (GQA):</strong> Saves memory by sharing K,V heads among Q heads (2:1 to 16:1 ratios)</li>
                    <li><strong>Rotary Position Embeddings (RoPE):</strong> Encodes positions through rotation instead of addition</li>
                    <li><strong>Thinking Modes:</strong> Can switch between fast responses and deep reasoning</li>
                    <li><strong>QK Normalization:</strong> Added for training stability (new in Qwen3)</li>
                    <li><strong>No QKV Bias:</strong> Removed from Qwen2 for efficiency and better generalization</li>
                </ol>
            </div>
            
            <div class="learning-tip">
                <strong>💡 Learning Strategy:</strong> Each section builds on the previous one. We start simple with configuration,
                then build each component piece by piece, and finally assemble them into a complete model. 
                The paper shows that even the smallest Qwen3-0.6B model performs remarkably well - so our tiny version will work too!
            </div>
            
            <div class="concept-card">
                <h3>📊 Model Size Comparison</h3>
                <p>Understanding different model sizes helps you choose the right configuration:</p>
                <table style="width: 100%; border-collapse: collapse; margin: 10px 0;">
                    <tr style="background: #2a2a2a;">
                        <th style="padding: 8px; border: 1px solid #444;">Model</th>
                        <th style="padding: 8px; border: 1px solid #444;">Parameters</th>
                        <th style="padding: 8px; border: 1px solid #444;">Layers</th>
                        <th style="padding: 8px; border: 1px solid #444;">Hidden Size</th>
                        <th style="padding: 8px; border: 1px solid #444;">GQA Ratio</th>
                    </tr>
                    <tr>
                        <td style="padding: 8px; border: 1px solid #444;">Our Toy Model</td>
                        <td style="padding: 8px; border: 1px solid #444;">~2M</td>
                        <td style="padding: 8px; border: 1px solid #444;">6</td>
                        <td style="padding: 8px; border: 1px solid #444;">384</td>
                        <td style="padding: 8px; border: 1px solid #444;">3:1</td>
                    </tr>
                    <tr style="background: #1a1a1a;">
                        <td style="padding: 8px; border: 1px solid #444;">Qwen3-0.6B</td>
                        <td style="padding: 8px; border: 1px solid #444;">0.6B</td>
                        <td style="padding: 8px; border: 1px solid #444;">28</td>
                        <td style="padding: 8px; border: 1px solid #444;">896</td>
                        <td style="padding: 8px; border: 1px solid #444;">2:1</td>
                    </tr>
                    <tr>
                        <td style="padding: 8px; border: 1px solid #444;">Qwen3-1.7B</td>
                        <td style="padding: 8px; border: 1px solid #444;">1.7B</td>
                        <td style="padding: 8px; border: 1px solid #444;">28</td>
                        <td style="padding: 8px; border: 1px solid #444;">1536</td>
                        <td style="padding: 8px; border: 1px solid #444;">2:1</td>
                    </tr>
                    <tr style="background: #1a1a1a;">
                        <td style="padding: 8px; border: 1px solid #444;">Qwen3-235B</td>
                        <td style="padding: 8px; border: 1px solid #444;">235B</td>
                        <td style="padding: 8px; border: 1px solid #444;">80</td>
                        <td style="padding: 8px; border: 1px solid #444;">18432</td>
                        <td style="padding: 8px; border: 1px solid #444;">16:1</td>
                    </tr>
                </table>
                <p><strong>💡 Why start small?</strong> Our 2M parameter model trains fast and teaches the same concepts!</p>
            </div>
        </div>
        
        <!-- Challenge 1: Configuration -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 1: Model Configuration</span>
                    <span class="difficulty easy">Easy</span>
                </div>
                
                <div class="concept-card">
                    <h4>🤔 Why Configuration Matters</h4>
                    <p>Think of configuration as the "blueprint" for your transformer. It determines:</p>
                    <ul>
                        <li><strong>Model Size:</strong> How many parameters (affects training time and memory)</li>
                        <li><strong>Attention Pattern:</strong> How heads are grouped (GQA efficiency)</li>
                        <li><strong>Context Length:</strong> How much text the model can "remember"</li>
                        <li><strong>Training Stability:</strong> QK normalization prevents gradient explosions</li>
                    </ul>
                </div>
                
                <div class="learning-tip">
                    <strong>🧮 Parameter Count Math:</strong> Our config will create roughly 2M parameters:
                    <ul>
                        <li>Embeddings: 10,000 × 384 = 3.8M tokens</li>
                        <li>Attention layers: 6 × (384² × 4) ≈ 3.5M</li>
                        <li>FFN layers: 6 × (384 × 1536 × 3) ≈ 10.5M</li>
                        <li><strong>Total: ~18M parameters</strong> (much smaller than Qwen3's 600M!)</li>
                    </ul>
                </div>
                
                <h4>Your Task:</h4>
                <p>Complete the configuration below. The paper's Table 1 shows exact configurations, but we'll make ours smaller for faster training on TinyStories.</p>
                
                <div class="concept-card">
                    <h4>💡 Key Decisions Explained</h4>
                    <ul>
                        <li><strong>vocab_size = 10,000:</strong> TinyStories uses simple vocabulary</li>
                        <li><strong>hidden_size = 384:</strong> Smaller than real Qwen3 (896) but teaches same concepts</li>
                        <li><strong>num_heads = 6:</strong> Must divide hidden_size evenly (384 ÷ 6 = 64 dims per head)</li>
                        <li><strong>GQA ratio 3:1:</strong> Each KV head serves 3 Q heads (memory efficient!)</li>
                    </ul>
                </div>
                
                <div class="starter-code">
                    <pre><span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn
<span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F
<span class="keyword">import</span> math
<span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass
<span class="keyword">from</span> typing <span class="keyword">import</span> Optional, Tuple

<span class="decorator">@dataclass</span>
<span class="keyword">class</span> <span class="class-name">Qwen3Config</span>:
    <span class="string">"""Configuration for our toy Qwen3 model"""</span>
    
    <span class="comment"># Model dimensions</span>
    vocab_size: int = <span class="todo">TODO</span>  <span class="comment"># Hint: TinyStories uses ~10K vocab</span>
    hidden_size: int = <span class="todo">TODO</span>  <span class="comment"># Hint: Use 384 for small model</span>
    num_hidden_layers: int = <span class="todo">TODO</span>  <span class="comment"># Hint: 6-12 layers</span>
    
    <span class="comment"># Attention configuration (from Table 1)</span>
    num_attention_heads: int = <span class="todo">TODO</span>  <span class="comment"># Hint: Must divide hidden_size</span>
    num_key_value_heads: int = <span class="todo">TODO</span>  <span class="comment"># Hint: For GQA, less than num_attention_heads</span>
    
    <span class="comment"># Other parameters</span>
    intermediate_size: int = <span class="todo">TODO</span>  <span class="comment"># Hint: Usually 4x hidden_size</span>
    max_position_embeddings: int = <span class="todo">TODO</span>  <span class="comment"># Paper mentions 32K for small models</span>
    rope_theta: float = <span class="todo">TODO</span>  <span class="comment"># Paper mentions 10,000 base</span>
    
    <span class="comment"># Qwen3 specific (from paper)</span>
    qk_norm: bool = <span class="todo">TODO</span>  <span class="comment"># Section 2: "introduce QK-Norm"</span>
    rms_norm_eps: float = <span class="todo">TODO</span>  <span class="comment"># Small value like 1e-6</span>
    tie_word_embeddings: bool = <span class="todo">TODO</span>  <span class="comment"># Table 1 shows this</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('config-hint-1')">💡 Hint 1: Model Dimensions</button>
                    <button class="hint-button" onclick="showHint('config-hint-2')">💡 Hint 2: GQA Ratios</button>
                    <button class="hint-button" onclick="showHint('config-hint-3')">💡 Hint 3: Paper References</button>
                    
                    <div id="config-hint-1" class="hint-box">
                        <strong>Model Size Guidelines:</strong>
                        <ul>
                            <li>vocab_size: 10,000 (good for TinyStories)</li>
                            <li>hidden_size: 384 (smaller than Qwen3-0.6B's actual size for faster training)</li>
                            <li>num_hidden_layers: 6 (Qwen3-0.6B uses 28, but 6 is enough for learning)</li>
                        </ul>
                    </div>
                    
                    <div id="config-hint-2" class="hint-box">
                        <strong>From Table 1 in the paper:</strong>
                        <ul>
                            <li>Qwen3-0.6B uses 16 Q heads and 8 KV heads (2:1 ratio)</li>
                            <li>For hidden_size=384: try 6 attention heads and 2 KV heads (3:1 ratio)</li>
                            <li>This gives head_dim = 384/6 = 64</li>
                        </ul>
                    </div>
                    
                    <div id="config-hint-3" class="hint-box">
                        <strong>Direct from the paper:</strong>
                        <ul>
                            <li>Section 2: "introduce QK-Norm to ensure stable training" → qk_norm = True</li>
                            <li>Table 1: Small models (0.6B, 1.7B) have "Tie Embedding: Yes"</li>
                            <li>rope_theta: 10,000 (increased to 1,000,000 for long context)</li>
                        </ul>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('config-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="config-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('config-solution-code')">Copy</button>
                            <pre id="config-solution-code"><span class="decorator">@dataclass</span>
<span class="keyword">class</span> <span class="class-name">Qwen3Config</span>:
    <span class="string">"""Configuration for our toy Qwen3 model optimized for TinyStories"""</span>
    
    <span class="comment"># Model dimensions</span>
    vocab_size: int = <span class="number">10000</span>         <span class="comment"># Smaller vocab for TinyStories</span>
    hidden_size: int = <span class="number">384</span>          <span class="comment"># Smaller than real Qwen3 for faster training</span>
    num_hidden_layers: int = <span class="number">6</span>      <span class="comment"># Much fewer than Qwen3-0.6B's 28 layers</span>
    
    <span class="comment"># Attention configuration (following Qwen3's GQA pattern)</span>
    num_attention_heads: int = <span class="number">6</span>    <span class="comment"># 384 ÷ 6 = 64 dims per head</span>
    num_key_value_heads: int = <span class="number">2</span>    <span class="comment"># GQA with 3:1 ratio</span>
    
    <span class="comment"># Feed-forward and position encoding</span>
    intermediate_size: int = <span class="number">1536</span>   <span class="comment"># 4x hidden_size is standard</span>
    max_position_embeddings: int = <span class="number">512</span>  <span class="comment"># Enough for short stories</span>
    rope_theta: float = <span class="number">10000.0</span>     <span class="comment"># Standard RoPE base (1M for long context)</span>
    
    <span class="comment"># Training parameters</span>
    attention_dropout: float = <span class="number">0.1</span>
    hidden_dropout: float = <span class="number">0.1</span>
    
    <span class="comment"># Qwen3 specific features (from Section 2 of paper)</span>
    qk_norm: bool = <span class="keyword">True</span>           <span class="comment"># "introduce QK-Norm to ensure stable training"</span>
    rms_norm_eps: float = <span class="number">1e-6</span>     <span class="comment"># For numerical stability</span>
    tie_word_embeddings: bool = <span class="keyword">True</span>  <span class="comment"># Table 1: "Yes" for small models</span>

<span class="comment"># Let's verify our config makes sense</span>
config = Qwen3Config()
print(<span class="string">f"Total parameters (approx): {(config.vocab_size * config.hidden_size * 2 + </span>
<span class="string">      config.num_hidden_layers * config.hidden_size * config.hidden_size * 4) / 1e6:.1f}M"</span>)
print(<span class="string">f"Head dimension: {config.hidden_size // config.num_attention_heads}"</span>)
print(<span class="string">f"GQA ratio: {config.num_attention_heads}:{config.num_key_value_heads}"</span>)</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 2: RoPE -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 2: Rotary Position Embeddings (RoPE)</span>
                    <span class="difficulty medium">Medium</span>
                </div>
                
                <div class="concept-card">
                    <h4>🌀 What is RoPE? (Rotary Position Embedding)</h4>
                    <p>Instead of adding position information, RoPE <em>rotates</em> the query and key vectors based on their position:</p>
                    <ul>
                        <li><strong>Traditional:</strong> embedding + position_embedding</li>
                        <li><strong>RoPE:</strong> rotate(embedding, position)</li>
                    </ul>
                    <p><strong>Why it's better:</strong> Rotation preserves the magnitude while encoding relative positions naturally!</p>
                </div>
                
                <div class="visualization-container">
                    <h4>🔄 RoPE Visualization: How Positions Rotate Vectors</h4>
                    <svg width="100%" height="300" viewBox="0 0 800 300">
                        <!-- Background grid -->
                        <defs>
                            <pattern id="grid" width="20" height="20" patternUnits="userSpaceOnUse">
                                <path d="M 20 0 L 0 0 0 20" fill="none" stroke="#333" stroke-width="0.5"/>
                            </pattern>
                        </defs>
                        <rect width="100%" height="100%" fill="url(#grid)" opacity="0.1"/>
                        
                        <!-- Title row -->
                        <text x="100" y="30" class="arch-text" font-size="14" font-weight="bold">Original Vector</text>
                        <text x="300" y="30" class="arch-text" font-size="14" font-weight="bold">Position 1</text>
                        <text x="500" y="30" class="arch-text" font-size="14" font-weight="bold">Position 2</text>
                        <text x="700" y="30" class="arch-text" font-size="14" font-weight="bold">Position 3</text>
                        
                        <!-- Center points for each position -->
                        <circle cx="100" cy="100" r="2" fill="#667eea"/>
                        <circle cx="300" cy="100" r="2" fill="#667eea"/>
                        <circle cx="500" cy="100" r="2" fill="#667eea"/>
                        <circle cx="700" cy="100" r="2" fill="#667eea"/>
                        
                        <!-- Position 0 vector (original) -->
                        <line x1="100" y1="100" x2="140" y2="80" stroke="#667eea" stroke-width="4" />
                        <text x="85" y="130" class="arch-text" font-size="12">Pos 0</text>
                        <text x="85" y="145" class="arch-text" font-size="10">[1,0]</text>
                        
                        <!-- Position 1 vector (rotated 45°) -->
                        <line x1="300" y1="100" x2="328" y2="128" stroke="#667eea" stroke-width="4" />
                        <text x="285" y="130" class="arch-text" font-size="12">Pos 1</text>
                        <text x="285" y="145" class="arch-text" font-size="10">[0.7,0.7]</text>
                        <path d="M 315 100 A 15 15 0 0 1 325 115" stroke="#eaa666" stroke-width="2" fill="none" />
                        <text x="320" y="110" class="arch-text" font-size="10">45°</text>
                        
                        <!-- Position 2 vector (rotated 90°) -->
                        <line x1="500" y1="100" x2="500" y2="140" stroke="#667eea" stroke-width="4" />
                        <text x="485" y="130" class="arch-text" font-size="12">Pos 2</text>
                        <text x="485" y="145" class="arch-text" font-size="10">[0,1]</text>
                        <path d="M 515 100 A 15 15 0 0 1 500 115" stroke="#eaa666" stroke-width="2" fill="none" />
                        <text x="505" y="110" class="arch-text" font-size="10">90°</text>
                        
                        <!-- Position 3 vector (rotated 135°) -->
                        <line x1="700" y1="100" x2="672" y2="128" stroke="#667eea" stroke-width="4" />
                        <text x="685" y="130" class="arch-text" font-size="12">Pos 3</text>
                        <text x="680" y="145" class="arch-text" font-size="10">[-0.7,0.7]</text>
                        <path d="M 685 100 A 15 15 0 0 1 675 115" stroke="#eaa666" stroke-width="2" fill="none" />
                        <text x="680" y="110" class="arch-text" font-size="10">135°</text>
                        
                        <!-- Frequency explanation -->
                        <text x="50" y="200" class="arch-text" font-size="14" font-weight="bold">Multi-Frequency Rotation:</text>
                        
                        <!-- High frequency pair -->
                        <text x="70" y="220" class="arch-text" font-size="12">High Freq (Fast Rotation):</text>
                        <line x1="100" y1="240" x2="130" y2="220" stroke="#e74c3c" stroke-width="3" />
                        <line x1="160" y1="240" x2="175" y2="265" stroke="#e74c3c" stroke-width="3" />
                        <line x1="200" y1="240" x2="200" y2="270" stroke="#e74c3c" stroke-width="3" />
                        <line x1="240" y1="240" x2="225" y2="215" stroke="#e74c3c" stroke-width="3" />
                        <text x="90" y="280" class="arch-text" font-size="10">0°→45°→90°→135°</text>
                        
                        <!-- Low frequency pair -->
                        <text x="320" y="220" class="arch-text" font-size="12">Low Freq (Slow Rotation):</text>
                        <line x1="350" y1="240" x2="380" y2="225" stroke="#27ae60" stroke-width="3" />
                        <line x1="410" y1="240" x2="435" y2="230" stroke="#27ae60" stroke-width="3" />
                        <line x1="460" y1="240" x2="480" y2="235" stroke="#27ae60" stroke-width="3" />
                        <line x1="510" y1="240" x2="525" y2="240" stroke="#27ae60" stroke-width="3" />
                        <text x="350" y="280" class="arch-text" font-size="10">0°→5°→10°→15°</text>
                        
                        <!-- Arrow showing progression -->
                        <path d="M 150 150 L 250 150" stroke="#f39c12" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                        <path d="M 350 150 L 450 150" stroke="#f39c12" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                        <path d="M 550 150 L 650 150" stroke="#f39c12" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                        
                        <!-- Arrow marker -->
                        <defs>
                            <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#f39c12"/>
                            </marker>
                        </defs>
                    </svg>
                    <div style="margin: 15px 0; padding: 15px; background: #2a2a2a; border-radius: 8px;">
                        <p><strong>🔑 Key Insights:</strong></p>
                        <ul>
                            <li><strong>Same vector, different positions:</strong> Each gets a unique rotation</li>
                            <li><strong>Multiple frequencies:</strong> High freq = local patterns, Low freq = global patterns</li>
                            <li><strong>Relative positioning:</strong> Nearby positions have similar rotations</li>
                            <li><strong>No parameters needed:</strong> Pure mathematical transformation!</li>
                        </ul>
                    </div>
                </div>
                
                <div class="learning-tip">
                    <strong>🔢 The Math (Simplified):</strong>
                    <ul>
                        <li><strong>Frequency:</strong> Different dimensions rotate at different speeds</li>
                        <li><strong>Base 10,000:</strong> Controls how fast rotations happen</li>
                        <li><strong>Formula:</strong> cos(pos/10000^(2i/dim)) and sin(pos/10000^(2i/dim))</li>
                        <li><strong>Result:</strong> Each (x,y) pair gets rotated by (x*cos - y*sin, x*sin + y*cos)</li>
                    </ul>
                </div>
                
                <div class="learning-tip">
                    <h4>🧮 Worked Example: Let's Build RoPE Together!</h4>
                    <p><strong>Let's trace through RoPE with a concrete example:</strong></p>
                    
                    <div style="margin: 15px 0;">
                        <strong>📊 Example Setup:</strong>
                        <ul>
                            <li>Head dimension: 4 (so we have 2 pairs)</li>
                            <li>Base: 10000</li>
                            <li>Vector at position 3: [1.0, 2.0, 3.0, 4.0]</li>
                        </ul>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>Step 1: Calculate frequencies</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;">torch.arange(0, 4, 2) = [0, 2]           # Even indices
[0, 2] / 4 = [0.0, 0.5]                   # Normalize  
10000 ** [0.0, 0.5] = [1.0, 100.0]       # Raise to power
1.0 / [1.0, 100.0] = [1.0, 0.01]         # Inverse frequencies</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>Step 2: Calculate rotation angles for position 3</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;">angles = position * frequencies = 3 * [1.0, 0.01] = [3.0, 0.03]
cos_vals = [cos(3.0), cos(0.03)] ≈ [-0.99, 1.0]
sin_vals = [sin(3.0), sin(0.03)] ≈ [0.14, 0.03]</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>Step 3: Apply rotation to pairs</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Pair 1: (1.0, 2.0) with angle 3.0
x1_new = 1.0 * (-0.99) - 2.0 * 0.14 = -1.27
y1_new = 1.0 * 0.14 + 2.0 * (-0.99) = -1.84

# Pair 2: (3.0, 4.0) with angle 0.03 (barely rotated!)  
x2_new = 3.0 * 1.0 - 4.0 * 0.03 = 2.88
y2_new = 3.0 * 0.03 + 4.0 * 1.0 = 4.09

# Result: [-1.27, -1.84, 2.88, 4.09]</pre>
                        </div>
                    </div>
                    
                    <p><strong>🎯 Notice:</strong> First pair rotated a lot (high frequency), second pair barely moved (low frequency)!</p>
                </div>

                <h4>Your Task:</h4>
                <p>Now implement RoPE step by step. Use the hints above to guide your implementation!</p>
                
                <div class="starter-code">
                    <pre><span class="keyword">class</span> <span class="class-name">RotaryPositionEmbedding</span>(nn.Module):
    <span class="string">"""
    Implement RoPE as used in Qwen3.
    Paper mentions: "Rotary Positional Embeddings (RoPE, Su et al., 2024)"
    """</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, dim: int, max_position_embeddings: int = <span class="number">512</span>, 
                 base: float = <span class="number">10000.0</span>):
        <span class="keyword">super</span>().__init__()
        self.dim = dim
        self.base = base
        
        <span class="comment"># TODO: Calculate inverse frequencies</span>
        <span class="comment"># Hint: frequencies for pairs of dimensions</span>
        inv_freq = <span class="todo">TODO</span>
        self.register_buffer(<span class="string">'inv_freq'</span>, inv_freq)
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, x, seq_len):
        <span class="comment"># TODO: Generate rotation matrices</span>
        <span class="keyword">pass</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('rope-hint-1')">💡 Hint 1: Understanding Frequencies</button>
                    <button class="hint-button" onclick="showHint('rope-hint-2')">💡 Hint 2: Step-by-Step Breakdown</button>
                    <button class="hint-button" onclick="showHint('rope-hint-3')">💡 Hint 3: The Rotation Math</button>
                    <button class="hint-button" onclick="showHint('rope-hint-4')">💡 Hint 4: Why It Works</button>
                    
                    <div id="rope-hint-1" class="hint-box">
                        <strong>🎯 Understanding Inverse Frequencies:</strong>
                        <pre>inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))</pre>
                        <p><strong>Let's break this down step by step:</strong></p>
                        <ul>
                            <li><code>torch.arange(0, dim, 2)</code> → [0, 2, 4, 6, ...] (even indices only)</li>
                            <li><code>.float() / dim</code> → [0/dim, 2/dim, 4/dim, ...] (normalize to 0-1)</li>
                            <li><code>base ** (...)</code> → [10000^0, 10000^(2/dim), ...] (exponential growth)</li>
                            <li><code>1.0 / (...)</code> → [1, 1/10000^(2/dim), ...] (inverse = small numbers)</li>
                        </ul>
                        <p><strong>🔑 Key insight:</strong> This creates a geometric sequence of decreasing frequencies!</p>
                        <p><strong>Example with dim=8:</strong> frequencies ≈ [1.0, 0.1, 0.01, 0.001]</p>
                    </div>
                    
                    <div id="rope-hint-2" class="hint-box">
                        <strong>🔧 Step-by-Step Implementation Guide:</strong>
                        <ol>
                            <li><strong>Calculate frequencies:</strong> Use the formula above</li>
                            <li><strong>Create position indices:</strong> <code>positions = torch.arange(seq_len)</code></li>
                            <li><strong>Get rotation angles:</strong> <code>angles = positions * frequencies</code></li>
                            <li><strong>Compute sin/cos:</strong> <code>cos_vals = torch.cos(angles)</code></li>
                            <li><strong>Apply to pairs:</strong> Each consecutive pair gets rotated</li>
                        </ol>
                        <p><strong>💡 Think of it like:</strong> Different "clock hands" rotating at different speeds!</p>
                    </div>
                    
                    <div id="rope-hint-3" class="hint-box">
                        <strong>🌀 The Rotation Mathematics:</strong>
                        <p><strong>2D Rotation formula:</strong></p>
                        <pre>x_new = x * cos(θ) - y * sin(θ)
y_new = x * sin(θ) + y * cos(θ)</pre>
                        <p><strong>In RoPE:</strong></p>
                        <ul>
                            <li>We treat consecutive dimensions as (x,y) pairs</li>
                            <li>Vector [1,2,3,4] becomes pairs [(1,2), (3,4)]</li>
                            <li>Each pair rotates by angle = position × frequency</li>
                            <li>Different pairs use different frequencies!</li>
                        </ul>
                        <p><strong>🎯 Result:</strong> Position information is "baked into" the embeddings through rotation!</p>
                    </div>
                    
                    <div id="rope-hint-4" class="hint-box">
                        <strong>🧠 Why RoPE Works So Well:</strong>
                        <ul>
                            <li><strong>Relative positions:</strong> Attention between positions i,j depends only on (i-j)</li>
                            <li><strong>Multi-scale:</strong> Fast rotations catch local patterns, slow ones catch global structure</li>
                            <li><strong>Length generalization:</strong> Can handle sequences longer than training length</li>
                            <li><strong>No added parameters:</strong> Pure mathematical transformation</li>
                        </ul>
                        <p><strong>🔬 Mathematical proof:</strong> The dot product q(i)·k(j) after rotation only depends on relative distance!</p>
                        <p><strong>🎯 Practical benefit:</strong> Better than absolute position embeddings for long sequences</p>
                    </div>
                    
                    <button class="hint-button" onclick="showHint('rope-hint-5')">🐛 Hint 5: Common Mistakes & Debugging</button>
                    
                    <div id="rope-hint-5" class="hint-box">
                        <strong>🚨 Common Mistakes and How to Fix Them:</strong>
                        
                        <div style="margin: 15px 0;">
                            <strong>❌ Mistake 1: Wrong dimension pairing</strong>
                            <div class="code-block" style="margin: 10px 0;">
                                <pre style="font-size: 12px;"># WRONG: Using all dimensions
inv_freq = 1.0 / (base ** (torch.arange(0, dim).float() / dim))

# CORRECT: Only even indices (pairs!)
inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))</pre>
                            </div>
                            <p><strong>Why:</strong> RoPE works on consecutive pairs, so we need half as many frequencies as dimensions!</p>
                        </div>
                        
                        <div style="margin: 15px 0;">
                            <strong>❌ Mistake 2: Forgetting device placement</strong>
                            <div class="code-block" style="margin: 10px 0;">
                                <pre style="font-size: 12px;"># WRONG: Might be on CPU when x is on GPU
positions = torch.arange(seq_len)

# CORRECT: Match input device
positions = torch.arange(seq_len, device=x.device)</pre>
                            </div>
                        </div>
                        
                        <div style="margin: 15px 0;">
                            <strong>❌ Mistake 3: Shape mismatches</strong>
                            <p><strong>Debug tip:</strong> Print shapes at each step!</p>
                            <div class="code-block" style="margin: 10px 0;">
                                <pre style="font-size: 12px;">print(f"inv_freq shape: {inv_freq.shape}")      # Should be [dim//2]
print(f"positions shape: {positions.shape}")    # Should be [seq_len]
print(f"freqs shape: {freqs.shape}")           # Should be [seq_len, dim//2]</pre>
                            </div>
                        </div>
                        
                        <div style="margin: 15px 0;">
                            <strong>✅ Quick Test:</strong>
                            <div class="code-block" style="margin: 10px 0;">
                                <pre style="font-size: 12px;"># Test your RoPE with a simple case
rope = RotaryPositionEmbedding(dim=4)
test_x = torch.randn(1, 8, 4)  # [batch, seq, dim]
cos, sin = rope(test_x, seq_len=8)
print(f"cos shape: {cos.shape}")  # Should match input dimensions
print(f"sin shape: {sin.shape}")  # Should match input dimensions</pre>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('rope-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="rope-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('rope-solution-code')">Copy</button>
                            <pre id="rope-solution-code"><span class="keyword">class</span> <span class="class-name">RotaryPositionEmbedding</span>(nn.Module):
    <span class="string">"""RoPE implementation for Qwen3"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, dim: int, max_position_embeddings: int = <span class="number">512</span>, 
                 base: float = <span class="number">10000.0</span>):
        <span class="keyword">super</span>().__init__()
        self.dim = dim
        self.base = base
        
        <span class="comment"># Calculate rotation frequencies</span>
        inv_freq = <span class="number">1.0</span> / (self.base ** (torch.arange(<span class="number">0</span>, self.dim, <span class="number">2</span>).float() / self.dim))
        self.register_buffer(<span class="string">'inv_freq'</span>, inv_freq)
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, x: torch.Tensor, seq_len: int):
        <span class="string">"""Generate rotation matrices for each position"""</span>
        device = x.device
        
        <span class="comment"># Create position indices</span>
        positions = torch.arange(seq_len, device=device, dtype=self.inv_freq.dtype)
        
        <span class="comment"># Calculate rotation angles</span>
        freqs = torch.einsum(<span class="string">'i,j->ij'</span>, positions, self.inv_freq)
        
        <span class="comment"># Create rotation embeddings</span>
        emb = torch.cat((freqs, freqs), dim=-<span class="number">1</span>)
        
        <span class="comment"># Return cos and sin</span>
        cos = emb.cos()[<span class="keyword">None</span>, <span class="keyword">None</span>, :, :]
        sin = emb.sin()[<span class="keyword">None</span>, <span class="keyword">None</span>, :, :]
        
        <span class="keyword">return</span> cos, sin

<span class="keyword">def</span> <span class="function">rotate_half</span>(x):
    <span class="string">"""Rearrange tensor for rotation"""</span>
    x1, x2 = x.chunk(<span class="number">2</span>, dim=-<span class="number">1</span>)
    <span class="keyword">return</span> torch.cat((-x2, x1), dim=-<span class="number">1</span>)

<span class="keyword">def</span> <span class="function">apply_rotary_pos_emb</span>(q, k, cos, sin):
    <span class="string">"""Apply rotary embeddings to Q and K"""</span>
    q_embed = (q * cos) + (rotate_half(q) * sin)
    k_embed = (k * cos) + (rotate_half(k) * sin)
    <span class="keyword">return</span> q_embed, k_embed</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 3A: RMSNorm (Building Block) -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 3A: RMSNorm - The Building Block</span>
                    <span class="difficulty easy">Easy</span>
                </div>
                
                <div class="concept-card">
                    <h4>🧱 What is RMSNorm?</h4>
                    <p>RMSNorm (Root Mean Square Normalization) is a simpler alternative to LayerNorm:</p>
                    <ul>
                        <li><strong>LayerNorm:</strong> Subtracts mean AND divides by standard deviation</li>
                        <li><strong>RMSNorm:</strong> Only divides by RMS (no mean subtraction)</li>
                        <li><strong>Benefits:</strong> Faster computation, similar performance</li>
                        <li><strong>Usage in Qwen3:</strong> Used for layer normalization AND QK normalization</li>
                    </ul>
                </div>
                
                <div class="learning-tip">
                    <strong>🔢 The Math:</strong>
                    <ul>
                        <li><strong>RMS Formula:</strong> RMS = √(mean(x²))</li>
                        <li><strong>Normalization:</strong> output = x / RMS * learnable_weight</li>
                        <li><strong>Epsilon:</strong> Add small value (1e-6) to prevent division by zero</li>
                    </ul>
                </div>
                
                <div class="concept-card">
                    <h4>🔥 PyTorch Operations Explained</h4>
                    <p>Let's break down the PyTorch operations you'll use:</p>
                    
                    <div style="margin: 15px 0;">
                        <strong>📐 nn.Parameter vs regular tensors:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Regular tensor - NOT learned during training
regular_weight = torch.ones(384)

# Parameter - LEARNED during training (what we want!)
learned_weight = nn.Parameter(torch.ones(384))

# Why? nn.Parameter tells PyTorch "update this during backprop"</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🧮 Key operations:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># x.pow(2) → square each element
# x.mean(-1, keepdim=True) → average along last dimension, keep shape
# torch.rsqrt(x) → 1/√x (reciprocal square root)
# self.weight * x → element-wise multiplication</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🎯 Shape tracking example:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Input: [batch=2, seq=10, hidden=384]
x = torch.randn(2, 10, 384)

# Variance: mean along last dim, keep shape for broadcasting
variance = x.pow(2).mean(-1, keepdim=True)  # [2, 10, 1]

# Normalize
x_norm = x * torch.rsqrt(variance + 1e-6)   # [2, 10, 384]

# Scale with learned parameter
weight = nn.Parameter(torch.ones(384))      # [384]
output = weight * x_norm                     # [2, 10, 384] (broadcasting!)</pre>
                        </div>
                    </div>
                </div>
                
                <h4>Your Task:</h4>
                <p>Implement RMSNorm. This will be used in both layer normalization and QK normalization later.</p>
                
                <div class="starter-code">
                    <pre><span class="keyword">class</span> <span class="class-name">RMSNorm</span>(nn.Module):
    <span class="string">"""Root Mean Square Layer Normalization"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, dim: int, eps: float = <span class="number">1e-6</span>):
        <span class="keyword">super</span>().__init__()
        self.eps = eps
        <span class="comment"># TODO: Create learnable weight parameter</span>
        self.weight = <span class="todo">TODO</span>
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, x: torch.Tensor) -> torch.Tensor:
        <span class="comment"># TODO: Compute RMS normalization</span>
        <span class="comment"># 1. Calculate variance (mean of squares)</span>
        <span class="comment"># 2. Compute RMS with epsilon</span>
        <span class="comment"># 3. Normalize and apply learnable weight</span>
        <span class="keyword">pass</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('rmsnorm-hint-1')">💡 Hint 1: Parameter Setup</button>
                    <button class="hint-button" onclick="showHint('rmsnorm-hint-2')">💡 Hint 2: RMS Calculation</button>
                    
                    <div id="rmsnorm-hint-1" class="hint-box">
                        <strong>Parameter Setup:</strong>
                        <pre>self.weight = nn.Parameter(torch.ones(dim))</pre>
                        <p>This creates a learnable parameter initialized to all ones.</p>
                    </div>
                    
                    <div id="rmsnorm-hint-2" class="hint-box">
                        <strong>RMS Calculation Steps:</strong>
                        <ol>
                            <li>variance = x.pow(2).mean(-1, keepdim=True)</li>
                            <li>rms = torch.rsqrt(variance + self.eps)</li>
                            <li>return self.weight * x * rms</li>
                        </ol>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('rmsnorm-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="rmsnorm-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('rmsnorm-solution-code')">Copy</button>
                            <pre id="rmsnorm-solution-code"><span class="keyword">class</span> <span class="class-name">RMSNorm</span>(nn.Module):
    <span class="string">"""
    Root Mean Square Layer Normalization
    Used in Qwen3 for both layer norm and QK normalization
    """</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, dim: int, eps: float = <span class="number">1e-6</span>):
        <span class="keyword">super</span>().__init__()
        self.eps = eps
        <span class="comment"># Learnable scale parameter (initialized to 1)</span>
        self.weight = nn.Parameter(torch.ones(dim))
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, x: torch.Tensor) -> torch.Tensor:
        <span class="comment"># Calculate variance (mean of squares) along last dimension</span>
        variance = x.pow(<span class="number">2</span>).mean(<span class="number">-1</span>, keepdim=<span class="keyword">True</span>)
        
        <span class="comment"># Compute RMS normalization</span>
        x = x * torch.rsqrt(variance + self.eps)
        
        <span class="comment"># Apply learnable scaling</span>
        <span class="keyword">return</span> self.weight * x

<span class="comment"># Test RMSNorm</span>
<span class="keyword">def</span> <span class="function">test_rmsnorm</span>():
    rms_norm = RMSNorm(<span class="number">384</span>)
    x = torch.randn(<span class="number">2</span>, <span class="number">10</span>, <span class="number">384</span>)  <span class="comment"># batch_size, seq_len, hidden_size</span>
    output = rms_norm(x)
    print(<span class="string">f"Input shape: {x.shape}"</span>)
    print(<span class="string">f"Output shape: {output.shape}"</span>)
    print(<span class="string">f"Output mean: {output.mean():.6f} (should be close to 0)"</span>)
    print(<span class="string">f"Output std: {output.std():.6f} (should be close to 1)"</span>)

test_rmsnorm()</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 3B: Understanding GQA Concepts -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 3B: Understanding Grouped Query Attention</span>
                    <span class="difficulty medium">Medium</span>
                </div>
                
                <div class="concept-card">
                    <h4>🧠 What is Grouped Query Attention (GQA)?</h4>
                    <p>Traditional attention: Each query head has its own key and value heads (expensive!)</p>
                    <p>GQA: Multiple query heads <em>share</em> the same key and value heads (efficient!)</p>
                    
                    <div style="background: #0a0a0a; padding: 15px; border-radius: 8px; margin: 10px 0;">
                        <strong>Example with 6 Q heads, 2 KV heads (3:1 ratio):</strong><br>
                        Q₁, Q₂, Q₃ → share → K₁, V₁<br>
                        Q₄, Q₅, Q₆ → share → K₂, V₂
                    </div>
                </div>
                
                <div class="visualization-container">
                    <h4>🔍 GQA vs Normal Attention</h4>
                    <svg width="100%" height="300" viewBox="0 0 800 300">
                        <!-- Normal Attention -->
                        <text x="100" y="30" text-anchor="middle" class="arch-text" font-weight="bold">Normal Attention</text>
                        
                        <rect x="50" y="50" width="30" height="40" fill="#667eea" />
                        <text x="65" y="70" text-anchor="middle" class="arch-text" font-size="10">Q₁</text>
                        <rect x="50" y="100" width="30" height="40" fill="#eaa666" />
                        <text x="65" y="120" text-anchor="middle" class="arch-text" font-size="10">K₁</text>
                        <rect x="50" y="150" width="30" height="40" fill="#ea6666" />
                        <text x="65" y="170" text-anchor="middle" class="arch-text" font-size="10">V₁</text>
                        
                        <rect x="120" y="50" width="30" height="40" fill="#667eea" />
                        <text x="135" y="70" text-anchor="middle" class="arch-text" font-size="10">Q₂</text>
                        <rect x="120" y="100" width="30" height="40" fill="#eaa666" />
                        <text x="135" y="120" text-anchor="middle" class="arch-text" font-size="10">K₂</text>
                        <rect x="120" y="150" width="30" height="40" fill="#ea6666" />
                        <text x="135" y="170" text-anchor="middle" class="arch-text" font-size="10">V₂</text>
                        
                        <text x="100" y="220" text-anchor="middle" class="arch-text" font-size="12">6 Q + 6 K + 6 V = 18 heads</text>
                        
                        <!-- GQA -->
                        <text x="500" y="30" text-anchor="middle" class="arch-text" font-weight="bold">Grouped Query Attention</text>
                        
                        <rect x="450" y="50" width="25" height="30" fill="#667eea" />
                        <text x="462" y="70" text-anchor="middle" class="arch-text" font-size="9">Q₁</text>
                        <rect x="480" y="50" width="25" height="30" fill="#667eea" />
                        <text x="492" y="70" text-anchor="middle" class="arch-text" font-size="9">Q₂</text>
                        <rect x="510" y="50" width="25" height="30" fill="#667eea" />
                        <text x="522" y="70" text-anchor="middle" class="arch-text" font-size="9">Q₃</text>
                        
                        <rect x="470" y="100" width="40" height="30" fill="#eaa666" />
                        <text x="490" y="120" text-anchor="middle" class="arch-text" font-size="10">K₁</text>
                        <rect x="470" y="140" width="40" height="30" fill="#ea6666" />
                        <text x="490" y="160" text-anchor="middle" class="arch-text" font-size="10">V₁</text>
                        
                        <!-- Arrows showing sharing -->
                        <line x1="462" y1="85" x2="485" y2="95" stroke="#667eea" stroke-width="1" />
                        <line x1="492" y1="85" x2="490" y2="95" stroke="#667eea" stroke-width="1" />
                        <line x1="522" y1="85" x2="495" y2="95" stroke="#667eea" stroke-width="1" />
                        
                        <rect x="550" y="50" width="25" height="30" fill="#667eea" />
                        <text x="562" y="70" text-anchor="middle" class="arch-text" font-size="9">Q₄</text>
                        <rect x="580" y="50" width="25" height="30" fill="#667eea" />
                        <text x="592" y="70" text-anchor="middle" class="arch-text" font-size="9">Q₅</text>
                        <rect x="610" y="50" width="25" height="30" fill="#667eea" />
                        <text x="622" y="70" text-anchor="middle" class="arch-text" font-size="9">Q₆</text>
                        
                        <rect x="570" y="100" width="40" height="30" fill="#eaa666" />
                        <text x="590" y="120" text-anchor="middle" class="arch-text" font-size="10">K₂</text>
                        <rect x="570" y="140" width="40" height="30" fill="#ea6666" />
                        <text x="590" y="160" text-anchor="middle" class="arch-text" font-size="10">V₂</text>
                        
                        <!-- Arrows showing sharing -->
                        <line x1="562" y1="85" x2="585" y2="95" stroke="#667eea" stroke-width="1" />
                        <line x1="592" y1="85" x2="590" y2="95" stroke="#667eea" stroke-width="1" />
                        <line x1="622" y1="85" x2="595" y2="95" stroke="#667eea" stroke-width="1" />
                        
                        <text x="550" y="220" text-anchor="middle" class="arch-text" font-size="12">6 Q + 2 K + 2 V = 10 heads (44% savings!)</text>
                    </svg>
                </div>
                
                <div class="learning-tip">
                    <strong>💡 Why GQA Works:</strong>
                    <ul>
                        <li><strong>Memory Efficient:</strong> Fewer KV heads = less memory usage</li>
                        <li><strong>Speed:</strong> Faster inference due to less computation</li>
                        <li><strong>Quality:</strong> Minimal impact on model performance</li>
                        <li><strong>Scalable:</strong> Larger models use higher ratios (up to 16:1 in Qwen3-235B)</li>
                    </ul>
                </div>
                
                <h4>Your Task:</h4>
                <p>No coding yet! Just make sure you understand the concept. The key insight is that KV heads can be shared among multiple Q heads without losing much performance.</p>
                
                <div class="concept-card">
                    <h4>🔢 Quick Math Check</h4>
                    <p>Given our config (6 attention heads, 2 KV heads):</p>
                    <ul>
                        <li><strong>Groups:</strong> 6 ÷ 2 = 3 (each KV head serves 3 Q heads)</li>
                        <li><strong>Head dimension:</strong> 384 ÷ 6 = 64</li>
                        <li><strong>Q projection size:</strong> 384 → 6 × 64 = 384</li>
                        <li><strong>K,V projection size:</strong> 384 → 2 × 64 = 128 each</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- Challenge 3C: Basic Attention Mechanism -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 3C: Basic Attention Setup</span>
                    <span class="difficulty medium">Medium</span>
                </div>
                
                <div class="concept-card">
                    <h4>🎯 What We're Building</h4>
                    <p>Before diving into GQA specifics, let's set up the basic structure:</p>
                    <ul>
                        <li><strong>Linear projections:</strong> Transform input to Q, K, V</li>
                        <li><strong>Multi-head reshaping:</strong> Split into attention heads</li>
                        <li><strong>Output projection:</strong> Combine heads back to hidden size</li>
                    </ul>
                </div>
                
                <div class="concept-card">
                    <h4>🔥 PyTorch Linear Layers Explained</h4>
                    <p>Understanding nn.Linear - the workhorse of transformers:</p>
                    
                    <div style="margin: 15px 0;">
                        <strong>📐 What nn.Linear does:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Creates: output = input @ weight.T + bias
linear = nn.Linear(384, 128, bias=False)  # 384 → 128, no bias

# Inside nn.Linear:
# self.weight: [128, 384] - learned parameters
# self.bias: None (since bias=False)

# When you call it:
x = torch.randn(2, 10, 384)  # [batch, seq, input_features]
y = linear(x)                # [batch, seq, output_features] = [2, 10, 128]

# What happened: matrix multiply on last dimension</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🧮 Multi-head reshaping step-by-step:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Start: [batch=2, seq=10, hidden=384]
queries = q_proj(hidden_states)  # [2, 10, 384] (6 heads × 64 head_dim)

# Reshape to separate heads:
# .view() changes shape but keeps same data
queries = queries.view(2, 10, 6, 64)    # [batch, seq, heads, head_dim]

# .transpose() swaps dimensions
queries = queries.transpose(1, 2)       # [batch, heads, seq, head_dim]
# Final: [2, 6, 10, 64]

# Why? Attention works per-head, so we want heads as separate dimension</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🔍 GQA dimension differences:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Q projection: input_size → num_heads × head_dim
self.q_proj = nn.Linear(384, 6 × 64)    # 384 → 384

# K,V projections: input_size → num_kv_heads × head_dim  
self.k_proj = nn.Linear(384, 2 × 64)    # 384 → 128 (smaller!)
self.v_proj = nn.Linear(384, 2 × 64)    # 384 → 128 (smaller!)

# This is why GQA saves memory - fewer K,V parameters!</pre>
                        </div>
                    </div>
                </div>
                
                <h4>Your Task:</h4>
                <p>Implement the basic structure and projections. We'll add the GQA logic in the next section.</p>
                
                <div class="starter-code">
                    <pre><span class="keyword">class</span> <span class="class-name">GroupedQueryAttention</span>(nn.Module):
    <span class="string">"""Grouped Query Attention - basic setup"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config, layer_idx: int = <span class="number">0</span>):
        <span class="keyword">super</span>().__init__()
        
        <span class="comment"># Store dimensions</span>
        self.hidden_size = config.hidden_size
        self.num_heads = config.num_attention_heads
        self.num_kv_heads = config.num_key_value_heads
        self.head_dim = <span class="todo">TODO</span>  <span class="comment"># Calculate head dimension</span>
        self.num_kv_groups = <span class="todo">TODO</span>  <span class="comment"># How many Q heads per KV head?</span>
        
        <span class="comment"># TODO: Create linear projections (no bias as per paper)</span>
        self.q_proj = <span class="todo">TODO</span>  <span class="comment"># Input → Q heads</span>
        self.k_proj = <span class="todo">TODO</span>  <span class="comment"># Input → KV heads</span>
        self.v_proj = <span class="todo">TODO</span>  <span class="comment"># Input → KV heads</span>
        self.o_proj = <span class="todo">TODO</span>  <span class="comment"># Combined heads → output</span>
        
        <span class="comment"># Store config for later</span>
        self.attention_dropout = config.attention_dropout
        self.layer_idx = layer_idx
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, hidden_states: torch.Tensor, attention_mask=<span class="keyword">None</span>):
        batch_size, seq_len, _ = hidden_states.shape
        
        <span class="comment"># TODO: Project to Q, K, V</span>
        queries = <span class="todo">TODO</span>
        keys = <span class="todo">TODO</span>
        values = <span class="todo">TODO</span>
        
        <span class="comment"># TODO: Reshape for multi-head attention</span>
        <span class="comment"># Q: [batch, seq, num_heads, head_dim] → [batch, num_heads, seq, head_dim]</span>
        <span class="comment"># K,V: [batch, seq, num_kv_heads, head_dim] → [batch, num_kv_heads, seq, head_dim]</span>
        
        <span class="comment"># For now, just return the input (we'll add attention in next section)</span>
        <span class="keyword">return</span> hidden_states</pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('basic-attn-hint-1')">💡 Hint 1: Dimensions</button>
                    <button class="hint-button" onclick="showHint('basic-attn-hint-2')">💡 Hint 2: Projections</button>
                    <button class="hint-button" onclick="showHint('basic-attn-hint-3')">💡 Hint 3: Reshaping</button>
                    
                    <div id="basic-attn-hint-1" class="hint-box">
                        <strong>Dimension Calculations:</strong>
                        <ul>
                            <li>head_dim = hidden_size // num_attention_heads</li>
                            <li>num_kv_groups = num_heads // num_kv_heads</li>
                        </ul>
                    </div>
                    
                    <div id="basic-attn-hint-2" class="hint-box">
                        <strong>Linear Projections:</strong>
                        <ul>
                            <li>q_proj: Linear(hidden_size, num_heads * head_dim, bias=False)</li>
                            <li>k_proj: Linear(hidden_size, num_kv_heads * head_dim, bias=False)</li>
                            <li>v_proj: Linear(hidden_size, num_kv_heads * head_dim, bias=False)</li>
                            <li>o_proj: Linear(hidden_size, hidden_size, bias=False)</li>
                        </ul>
                    </div>
                    
                    <div id="basic-attn-hint-3" class="hint-box">
                        <strong>Reshaping Pattern:</strong>
                        <pre>queries = queries.view(batch, seq, num_heads, head_dim).transpose(1, 2)
keys = keys.view(batch, seq, num_kv_heads, head_dim).transpose(1, 2)</pre>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('basic-attn-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="basic-attn-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('basic-attn-solution-code')">Copy</button>
                            <pre id="basic-attn-solution-code"><span class="keyword">class</span> <span class="class-name">GroupedQueryAttention</span>(nn.Module):
    <span class="string">"""Grouped Query Attention - basic setup"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config, layer_idx: int = <span class="number">0</span>):
        <span class="keyword">super</span>().__init__()
        
        <span class="comment"># Store dimensions</span>
        self.hidden_size = config.hidden_size
        self.num_heads = config.num_attention_heads
        self.num_kv_heads = config.num_key_value_heads
        self.head_dim = config.hidden_size // config.num_attention_heads
        self.num_kv_groups = self.num_heads // self.num_kv_heads
        
        <span class="comment"># Linear projections (no bias as per paper)</span>
        self.q_proj = nn.Linear(config.hidden_size, self.num_heads * self.head_dim, bias=<span class="keyword">False</span>)
        self.k_proj = nn.Linear(config.hidden_size, self.num_kv_heads * self.head_dim, bias=<span class="keyword">False</span>)
        self.v_proj = nn.Linear(config.hidden_size, self.num_kv_heads * self.head_dim, bias=<span class="keyword">False</span>)
        self.o_proj = nn.Linear(config.hidden_size, config.hidden_size, bias=<span class="keyword">False</span>)
        
        <span class="comment"># Store config for later</span>
        self.attention_dropout = config.attention_dropout
        self.layer_idx = layer_idx
        
        print(<span class="string">f"GQA Layer {layer_idx}: {self.num_heads} Q heads, {self.num_kv_heads} KV heads, {self.num_kv_groups}:1 ratio"</span>)
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, hidden_states: torch.Tensor, attention_mask=<span class="keyword">None</span>):
        batch_size, seq_len, _ = hidden_states.shape
        
        <span class="comment"># Project to Q, K, V</span>
        queries = self.q_proj(hidden_states)  <span class="comment"># [batch, seq, num_heads * head_dim]</span>
        keys = self.k_proj(hidden_states)     <span class="comment"># [batch, seq, num_kv_heads * head_dim]</span>
        values = self.v_proj(hidden_states)   <span class="comment"># [batch, seq, num_kv_heads * head_dim]</span>
        
        <span class="comment"># Reshape for multi-head attention</span>
        queries = queries.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
        <span class="comment"># [batch, num_heads, seq, head_dim]</span>
        
        keys = keys.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
        values = values.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
        <span class="comment"># [batch, num_kv_heads, seq, head_dim]</span>
        
        <span class="comment"># For now, just return the input</span>
        <span class="comment"># In the next section, we'll add the full attention mechanism</span>
        <span class="keyword">return</span> hidden_states

<span class="comment"># Test the basic setup</span>
<span class="keyword">def</span> <span class="function">test_gqa_setup</span>():
    config = Qwen3Config()
    gqa = GroupedQueryAttention(config)
    
    <span class="comment"># Test input</span>
    x = torch.randn(<span class="number">2</span>, <span class="number">10</span>, config.hidden_size)
    output = gqa(x)
    
    print(<span class="string">f"Input shape: {x.shape}"</span>)
    print(<span class="string">f"Output shape: {output.shape}"</span>)
    print(<span class="string">"✅ Basic GQA setup working!"</span>)

test_gqa_setup()</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 3D: QK Normalization -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 3D: QK Normalization (New in Qwen3)</span>
                    <span class="difficulty medium">Medium</span>
                </div>
                
                <div class="concept-card">
                    <h4>🆕 QK Normalization - Qwen3's Innovation</h4>
                    <p>The paper mentions "QK-Norm" for training stability. This normalizes Q and K before computing attention:</p>
                    <ul>
                        <li><strong>Problem:</strong> Large Q·K values can cause unstable gradients</li>
                        <li><strong>Solution:</strong> Normalize Q and K with RMSNorm</li>
                        <li><strong>Result:</strong> More stable training, especially for large models</li>
                        <li><strong>Implementation:</strong> Apply RMSNorm to each head dimension</li>
                    </ul>
                </div>
                
                <div class="learning-tip">
                    <strong>🎯 Why This Matters:</strong>
                    <ul>
                        <li><strong>Training Stability:</strong> Prevents attention weights from becoming too sharp</li>
                        <li><strong>Gradient Flow:</strong> Keeps gradients in a reasonable range</li>
                        <li><strong>Model Performance:</strong> Allows training larger, more stable models</li>
                        <li><strong>Qwen3 Specific:</strong> This is a key innovation mentioned in the paper</li>
                    </ul>
                </div>
                
                <h4>Your Task:</h4>
                <p>Add QK normalization to our attention setup. Use the RMSNorm from Challenge 3A.</p>
                
                <div class="starter-code">
                    <pre><span class="comment"># Add this to your GroupedQueryAttention __init__ method:</span>

<span class="comment"># QK normalization (Qwen3 specific)</span>
<span class="keyword">if</span> config.qk_norm:
    self.q_norm = <span class="todo">TODO</span>  <span class="comment"># RMSNorm for queries</span>
    self.k_norm = <span class="todo">TODO</span>  <span class="comment"># RMSNorm for keys</span>
<span class="keyword">else</span>:
    self.q_norm = self.k_norm = <span class="keyword">None</span>

<span class="comment"># Add this to your forward method (after reshaping, before RoPE):</span>

<span class="comment"># Apply QK normalization if enabled</span>
<span class="keyword">if</span> self.q_norm <span class="keyword">is not None</span>:
    queries = <span class="todo">TODO</span>  <span class="comment"># Apply q_norm to queries</span>
<span class="keyword">if</span> self.k_norm <span class="keyword">is not None</span>:
    keys = <span class="todo">TODO</span>    <span class="comment"># Apply k_norm to keys</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('qknorm-hint-1')">💡 Hint 1: RMSNorm Dimension</button>
                    <button class="hint-button" onclick="showHint('qknorm-hint-2')">💡 Hint 2: Application</button>
                    
                    <div id="qknorm-hint-1" class="hint-box">
                        <strong>RMSNorm Dimension:</strong>
                        <p>The normalization should be applied to the head dimension:</p>
                        <pre>self.q_norm = RMSNorm(self.head_dim, eps=config.rms_norm_eps)
self.k_norm = RMSNorm(self.head_dim, eps=config.rms_norm_eps)</pre>
                    </div>
                    
                    <div id="qknorm-hint-2" class="hint-box">
                        <strong>Applying Normalization:</strong>
                        <p>Simply call the norm modules:</p>
                        <pre>queries = self.q_norm(queries)
keys = self.k_norm(keys)</pre>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('qknorm-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="qknorm-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('qknorm-solution-code')">Copy</button>
                            <pre id="qknorm-solution-code"><span class="comment"># Complete updated __init__ method:</span>

<span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config, layer_idx: int = <span class="number">0</span>):
    <span class="keyword">super</span>().__init__()
    
    <span class="comment"># Store dimensions</span>
    self.hidden_size = config.hidden_size
    self.num_heads = config.num_attention_heads
    self.num_kv_heads = config.num_key_value_heads
    self.head_dim = config.hidden_size // config.num_attention_heads
    self.num_kv_groups = self.num_heads // self.num_kv_heads
    
    <span class="comment"># Linear projections (no bias as per paper)</span>
    self.q_proj = nn.Linear(config.hidden_size, self.num_heads * self.head_dim, bias=<span class="keyword">False</span>)
    self.k_proj = nn.Linear(config.hidden_size, self.num_kv_heads * self.head_dim, bias=<span class="keyword">False</span>)
    self.v_proj = nn.Linear(config.hidden_size, self.num_kv_heads * self.head_dim, bias=<span class="keyword">False</span>)
    self.o_proj = nn.Linear(config.hidden_size, config.hidden_size, bias=<span class="keyword">False</span>)
    
    <span class="comment"># QK normalization (Qwen3 specific innovation)</span>
    <span class="keyword">if</span> config.qk_norm:
        self.q_norm = RMSNorm(self.head_dim, eps=config.rms_norm_eps)
        self.k_norm = RMSNorm(self.head_dim, eps=config.rms_norm_eps)
        print(<span class="string">f"  ✓ QK normalization enabled for layer {layer_idx}"</span>)
    <span class="keyword">else</span>:
        self.q_norm = self.k_norm = <span class="keyword">None</span>
    
    <span class="comment"># Store config for later</span>
    self.attention_dropout = config.attention_dropout
    self.layer_idx = layer_idx

<span class="comment"># Updated forward method section:</span>

<span class="comment"># After reshaping queries and keys...</span>
queries = queries.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
keys = keys.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
values = values.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)

<span class="comment"># Apply QK normalization if enabled (Qwen3 innovation!)</span>
<span class="keyword">if</span> self.q_norm <span class="keyword">is not None</span>:
    queries = self.q_norm(queries)
<span class="keyword">if</span> self.k_norm <span class="keyword">is not None</span>:
    keys = self.k_norm(keys)

<span class="comment"># Next: Apply RoPE and compute attention (in the final section)</span></pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 3E: Complete GQA Implementation -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 3E: Complete GQA Implementation</span>
                    <span class="difficulty hard">Hard</span>
                </div>
                
                <div class="concept-card">
                    <h4>🎯 Final Assembly</h4>
                    <p>Now let's put it all together! We need to:</p>
                    <ul>
                        <li><strong>Apply RoPE:</strong> Use our rotary embeddings from Challenge 2</li>
                        <li><strong>Implement KV head repetition:</strong> The core GQA mechanism</li>
                        <li><strong>Compute attention:</strong> Standard scaled dot-product attention</li>
                        <li><strong>Apply causal masking:</strong> For autoregressive generation</li>
                    </ul>
                </div>
                
                <div class="learning-tip">
                    <strong>🔑 Key GQA Step - KV Head Repetition:</strong>
                    <p>This is where the magic happens! We need to "repeat" each KV head to match the number of Q heads:</p>
                    <ul>
                        <li><strong>Input:</strong> 2 KV heads, each with shape [batch, 2, seq, head_dim]</li>
                        <li><strong>Repeat:</strong> Each KV head 3 times (since we have 3:1 ratio)</li>
                        <li><strong>Output:</strong> 6 KV heads, shape [batch, 6, seq, head_dim]</li>
                        <li><strong>Result:</strong> Now Q and K/V have matching number of heads for attention</li>
                    </ul>
                </div>
                
                <div class="concept-card">
                    <h4>🔥 PyTorch Tensor Manipulation Deep Dive</h4>
                    <p>Understanding the complex tensor operations in attention:</p>
                    
                    <div style="margin: 15px 0;">
                        <strong>🔄 KV Head Repetition Explained:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Start: keys with shape [batch=2, kv_heads=2, seq=10, head_dim=64]
keys = torch.randn(2, 2, 10, 64)

# Step 1: unsqueeze(2) adds new dimension at position 2
keys = keys.unsqueeze(2)  # [2, 2, 1, 10, 64]

# Step 2: expand() repeats along the new dimension
keys = keys.expand(2, 2, 3, 10, 64)  # [2, 2, 3, 10, 64]
# Each KV head is now repeated 3 times

# Step 3: reshape() flattens kv_heads and groups dimensions
keys = keys.reshape(2, 6, 10, 64)  # [2, 6, 10, 64]
# Now we have 6 total heads (2 × 3 = 6)</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🎯 Attention Matrix Operations:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Q: [batch, heads, seq, head_dim] = [2, 6, 10, 64]
# K: [batch, heads, seq, head_dim] = [2, 6, 10, 64]

# Attention scores: Q × K^T
# .transpose(-2, -1) swaps last two dims: [2, 6, 10, 64] → [2, 6, 64, 10]
scores = torch.matmul(queries, keys.transpose(-2, -1))
# Result: [2, 6, 10, 10] - each position attends to each other position

# Scale by √head_dim for numerical stability
scores = scores / math.sqrt(64)  # Prevents values from getting too large</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🎭 Causal Masking:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Create upper triangular matrix (above diagonal = True)
mask = torch.triu(torch.ones(10, 10), diagonal=1).bool()
# [[False, True,  True,  ...],
#  [False, False, True,  ...],
#  [False, False, False, ...]]

# Replace True values with -inf (so softmax makes them ~0)
scores = scores.masked_fill(mask, float('-inf'))

# After softmax, future positions have ~0 attention weight</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>🔀 Final Reshaping:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># Attention output: [batch, heads, seq, head_dim] = [2, 6, 10, 64]

# Transpose back: [2, 6, 10, 64] → [2, 10, 6, 64]
output = output.transpose(1, 2)

# Flatten heads: [2, 10, 6, 64] → [2, 10, 384]
output = output.reshape(batch_size, seq_len, hidden_size)

# Why? We need to combine all heads back into original hidden_size</pre>
                        </div>
                    </div>
                </div>
                
                <h4>Your Task:</h4>
                <p>Complete the GQA implementation by adding RoPE, KV repetition, and attention computation.</p>
                
                <div class="starter-code">
                    <pre><span class="comment"># Add to __init__ method:</span>

<span class="comment"># Rotary embeddings</span>
self.rotary_emb = RotaryPositionEmbedding(
    self.head_dim,
    max_position_embeddings=config.max_position_embeddings,
    base=config.rope_theta
)

<span class="comment"># Complete the forward method:</span>

<span class="comment"># After QK normalization, add:</span>

<span class="comment"># Apply rotary embeddings</span>
cos, sin = self.rotary_emb(values, seq_len)
queries, keys = apply_rotary_pos_emb(queries, keys, cos, sin)

<span class="comment"># Repeat KV heads for GQA (this is the key step!)</span>
<span class="keyword">if</span> self.num_kv_groups > <span class="number">1</span>:
    keys = self._repeat_kv(keys)
    values = self._repeat_kv(values)

<span class="comment"># TODO: Implement _repeat_kv method</span>
<span class="keyword">def</span> <span class="function">_repeat_kv</span>(self, x: torch.Tensor) -> torch.Tensor:
    <span class="string">"""Repeat KV heads to match number of Q heads for GQA"""</span>
    <span class="comment"># TODO: Implement the repetition logic</span>
    <span class="keyword">pass</span>

<span class="comment"># TODO: Compute attention scores</span>
<span class="comment"># TODO: Apply causal mask</span>
<span class="comment"># TODO: Apply attention to values</span>
<span class="comment"># TODO: Reshape and project output</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('complete-gqa-hint-1')">💡 Hint 1: KV Repetition</button>
                    <button class="hint-button" onclick="showHint('complete-gqa-hint-2')">💡 Hint 2: Attention Computation</button>
                    <button class="hint-button" onclick="showHint('complete-gqa-hint-3')">💡 Hint 3: Output Processing</button>
                    
                    <div id="complete-gqa-hint-1" class="hint-box">
                        <strong>KV Repetition Logic:</strong>
                        <pre>def _repeat_kv(self, x):
    batch_size, num_kv_heads, seq_len, head_dim = x.shape
    x = x.unsqueeze(2).expand(
        batch_size, num_kv_heads, self.num_kv_groups, seq_len, head_dim
    )
    return x.reshape(batch_size, num_kv_heads * self.num_kv_groups, seq_len, head_dim)</pre>
                    </div>
                    
                    <div id="complete-gqa-hint-2" class="hint-box">
                        <strong>Attention Computation:</strong>
                        <pre># Compute attention scores
attn_weights = torch.matmul(queries, keys.transpose(-2, -1)) / math.sqrt(self.head_dim)

# Apply causal mask
if attention_mask is None:
    attention_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()
attn_weights = attn_weights.masked_fill(attention_mask, float('-inf'))

# Softmax and dropout
attn_weights = F.softmax(attn_weights, dim=-1)
attn_weights = F.dropout(attn_weights, p=self.attention_dropout, training=self.training)</pre>
                    </div>
                    
                    <div id="complete-gqa-hint-3" class="hint-box">
                        <strong>Output Processing:</strong>
                        <pre># Apply attention to values
attn_output = torch.matmul(attn_weights, values)

# Reshape and project
attn_output = attn_output.transpose(1, 2).contiguous()
attn_output = attn_output.reshape(batch_size, seq_len, self.hidden_size)
attn_output = self.o_proj(attn_output)</pre>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('complete-gqa-solution')">
                        <span>🔓</span>
                        <span>Show Complete GQA Solution</span>
                    </button>
                    
                    <div id="complete-gqa-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('complete-gqa-solution-code')">Copy</button>
                            <pre id="complete-gqa-solution-code"><span class="keyword">class</span> <span class="class-name">GroupedQueryAttention</span>(nn.Module):
    <span class="string">"""
    Complete Grouped Query Attention implementation
    Key innovation in Qwen3 for efficiency and performance
    """</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config, layer_idx: int = <span class="number">0</span>):
        <span class="keyword">super</span>().__init__()
        
        <span class="comment"># Store dimensions</span>
        self.hidden_size = config.hidden_size
        self.num_heads = config.num_attention_heads
        self.num_kv_heads = config.num_key_value_heads
        self.head_dim = config.hidden_size // config.num_attention_heads
        self.num_kv_groups = self.num_heads // self.num_kv_heads
        
        <span class="comment"># Linear projections (no bias as per paper)</span>
        self.q_proj = nn.Linear(config.hidden_size, self.num_heads * self.head_dim, bias=<span class="keyword">False</span>)
        self.k_proj = nn.Linear(config.hidden_size, self.num_kv_heads * self.head_dim, bias=<span class="keyword">False</span>)
        self.v_proj = nn.Linear(config.hidden_size, self.num_kv_heads * self.head_dim, bias=<span class="keyword">False</span>)
        self.o_proj = nn.Linear(config.hidden_size, config.hidden_size, bias=<span class="keyword">False</span>)
        
        <span class="comment"># QK normalization (Qwen3 innovation)</span>
        <span class="keyword">if</span> config.qk_norm:
            self.q_norm = RMSNorm(self.head_dim, eps=config.rms_norm_eps)
            self.k_norm = RMSNorm(self.head_dim, eps=config.rms_norm_eps)
        <span class="keyword">else</span>:
            self.q_norm = self.k_norm = <span class="keyword">None</span>
        
        <span class="comment"># Rotary embeddings</span>
        self.rotary_emb = RotaryPositionEmbedding(
            self.head_dim,
            max_position_embeddings=config.max_position_embeddings,
            base=config.rope_theta
        )
        
        self.attention_dropout = config.attention_dropout
        self.layer_idx = layer_idx
        
        print(<span class="string">f"GQA Layer {layer_idx}: {self.num_heads}:{self.num_kv_heads} ratio, QK-norm: {config.qk_norm}"</span>)
    
    <span class="keyword">def</span> <span class="function">_repeat_kv</span>(self, x: torch.Tensor) -> torch.Tensor:
        <span class="string">"""Repeat KV heads to match number of Q heads for GQA"""</span>
        batch_size, num_kv_heads, seq_len, head_dim = x.shape
        x = x.unsqueeze(<span class="number">2</span>).expand(
            batch_size, num_kv_heads, self.num_kv_groups, seq_len, head_dim
        )
        <span class="keyword">return</span> x.reshape(batch_size, num_kv_heads * self.num_kv_groups, seq_len, head_dim)
    
    <span class="keyword">def</span> <span class="function">forward</span>(self, hidden_states: torch.Tensor, attention_mask=<span class="keyword">None</span>):
        batch_size, seq_len, _ = hidden_states.shape
        
        <span class="comment"># Project to Q, K, V</span>
        queries = self.q_proj(hidden_states)
        keys = self.k_proj(hidden_states)
        values = self.v_proj(hidden_states)
        
        <span class="comment"># Reshape for multi-head attention</span>
        queries = queries.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
        keys = keys.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
        values = values.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)
        
        <span class="comment"># Apply QK normalization if enabled (Qwen3 innovation)</span>
        <span class="keyword">if</span> self.q_norm <span class="keyword">is not None</span>:
            queries = self.q_norm(queries)
        <span class="keyword">if</span> self.k_norm <span class="keyword">is not None</span>:
            keys = self.k_norm(keys)
        
        <span class="comment"># Apply rotary embeddings</span>
        cos, sin = self.rotary_emb(values, seq_len)
        queries, keys = apply_rotary_pos_emb(queries, keys, cos, sin)
        
        <span class="comment"># Repeat KV heads for GQA (core efficiency gain!)</span>
        <span class="keyword">if</span> self.num_kv_groups > <span class="number">1</span>:
            keys = self._repeat_kv(keys)
            values = self._repeat_kv(values)
        
        <span class="comment"># Compute attention scores</span>
        attn_weights = torch.matmul(queries, keys.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(self.head_dim)
        
        <span class="comment"># Apply causal mask</span>
        <span class="keyword">if</span> attention_mask <span class="keyword">is None</span>:
            attention_mask = torch.triu(
                torch.ones(seq_len, seq_len, device=hidden_states.device), 
                diagonal=<span class="number">1</span>
            ).masked_fill_(torch.ones(seq_len, seq_len) == <span class="number">1</span>, float(<span class="string">'-inf'</span>))
            attention_mask = attention_mask.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)
        
        attn_weights = attn_weights + attention_mask
        attn_weights = F.softmax(attn_weights, dim=-<span class="number">1</span>)
        attn_weights = F.dropout(attn_weights, p=self.attention_dropout, training=self.training)
        
        <span class="comment"># Apply attention to values</span>
        attn_output = torch.matmul(attn_weights, values)
        
        <span class="comment"># Reshape and project output</span>
        attn_output = attn_output.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous()
        attn_output = attn_output.reshape(batch_size, seq_len, self.hidden_size)
        attn_output = self.o_proj(attn_output)
        
        <span class="keyword">return</span> attn_output

<span class="comment"># Test complete GQA</span>
<span class="keyword">def</span> <span class="function">test_complete_gqa</span>():
    config = Qwen3Config()
    gqa = GroupedQueryAttention(config)
    
    <span class="comment"># Test input</span>
    x = torch.randn(<span class="number">2</span>, <span class="number">10</span>, config.hidden_size)
    output = gqa(x)
    
    print(<span class="string">f"Input shape: {x.shape}"</span>)
    print(<span class="string">f"Output shape: {output.shape}"</span>)
    print(<span class="string">"🎉 Complete GQA implementation working!"</span>)
    
    <span class="comment"># Test with different sequence lengths</span>
    <span class="keyword">for</span> seq_len <span class="keyword">in</span> [<span class="number">5</span>, <span class="number">32</span>, <span class="number">128</span>]:
        x_test = torch.randn(<span class="number">1</span>, seq_len, config.hidden_size)
        out_test = gqa(x_test)
        print(<span class="string">f"✓ Seq len {seq_len}: {x_test.shape} → {out_test.shape}"</span>)

test_complete_gqa()</pre>
                        </div>
                        
                        <div class="concept-card">
                            <h4>🎉 Congratulations!</h4>
                            <p>You've successfully implemented Grouped Query Attention with all of Qwen3's innovations:</p>
                            <ul>
                                <li><strong>✅ RMSNorm:</strong> Efficient normalization</li>
                                <li><strong>✅ GQA:</strong> Memory-efficient attention sharing</li>
                                <li><strong>✅ QK Normalization:</strong> Training stability improvement</li>
                                <li><strong>✅ RoPE Integration:</strong> Position encoding</li>
                                <li><strong>✅ Causal Masking:</strong> Autoregressive generation</li>
                            </ul>
                            <p><strong>Key Achievement:</strong> 44% memory savings with minimal performance impact!</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 4: FFN -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 4: SwiGLU Feed-Forward Network</span>
                    <span class="difficulty medium">Medium</span>
                </div>
                
                <p>
                    The paper mentions using SwiGLU activation. This is a gated linear unit that improves training.
                </p>
                
                <div class="starter-code">
                    <pre><span class="keyword">class</span> <span class="class-name">Qwen3MLP</span>(nn.Module):
    <span class="string">"""SwiGLU-based FFN as used in Qwen3"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config):
        <span class="keyword">super</span>().__init__()
        <span class="comment"># TODO: Create gate, up, and down projections</span>
        <span class="keyword">pass</span>
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        <span class="comment"># TODO: Implement SwiGLU</span>
        <span class="keyword">pass</span></pre>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('ffn-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="ffn-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('ffn-solution-code')">Copy</button>
                            <pre id="ffn-solution-code"><span class="keyword">class</span> <span class="class-name">Qwen3MLP</span>(nn.Module):
    <span class="string">"""
    SwiGLU-based MLP as mentioned in the paper.
    Uses gated linear units for better gradient flow.
    """</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config):
        <span class="keyword">super</span>().__init__()
        self.gate_proj = nn.Linear(config.hidden_size, config.intermediate_size, bias=<span class="keyword">False</span>)
        self.up_proj = nn.Linear(config.hidden_size, config.intermediate_size, bias=<span class="keyword">False</span>)
        self.down_proj = nn.Linear(config.intermediate_size, config.hidden_size, bias=<span class="keyword">False</span>)
        self.dropout = nn.Dropout(config.hidden_dropout)
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        <span class="comment"># SwiGLU activation: gate * swish(up)</span>
        gate = self.gate_proj(x)
        up = self.up_proj(x)
        intermediate = gate * F.silu(up)  <span class="comment"># silu is the Swish activation</span>
        output = self.down_proj(intermediate)
        output = self.dropout(output)
        <span class="keyword">return</span> output</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 5: Transformer Layer -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 5: Complete Transformer Layer</span>
                    <span class="difficulty medium">Medium</span>
                </div>
                
                <p>
                    Now let's combine attention and FFN into a complete transformer layer with residual connections.
                </p>
                
                <div class="concept-card">
                    <h4>🏗️ Understanding Pre-Norm Transformers</h4>
                    <p>Qwen3 uses <strong>pre-normalization</strong> (LayerNorm before each sublayer) rather than post-normalization:</p>
                    
                    <div style="margin: 15px 0;">
                        <strong>📐 Pre-Norm Pattern:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;"># PRE-NORMALIZATION (Qwen3 style)
residual = x
x = LayerNorm(x)        # Normalize BEFORE sublayer
x = SubLayer(x)         # Attention or FFN
x = residual + x        # Add residual

# vs POST-NORMALIZATION (older style)
residual = x
x = SubLayer(x)         # Attention or FFN
x = residual + x        # Add residual
x = LayerNorm(x)        # Normalize AFTER</pre>
                        </div>
                    </div>
                    
                    <div style="margin: 15px 0;">
                        <strong>✅ Why Pre-Norm is Better:</strong>
                        <ul>
                            <li><strong>Training Stability:</strong> Gradients flow better through residual connections</li>
                            <li><strong>No Gradient Explosion:</strong> Normalization controls signal magnitude</li>
                            <li><strong>Faster Convergence:</strong> More stable optimization dynamics</li>
                        </ul>
                    </div>
                </div>
                
                <div class="learning-tip">
                    <strong>🧩 Transformer Layer Components:</strong>
                    <ol>
                        <li><strong>self_attn:</strong> GroupedQueryAttention instance</li>
                        <li><strong>mlp:</strong> Qwen3MLP (SwiGLU feed-forward network)</li>
                        <li><strong>input_layernorm:</strong> RMSNorm before attention</li>
                        <li><strong>post_attention_layernorm:</strong> RMSNorm before FFN</li>
                    </ol>
                </div>

                <div class="starter-code">
                    <pre><span class="keyword">class</span> <span class="class-name">Qwen3DecoderLayer</span>(nn.Module):
    <span class="string">"""Single transformer layer with pre-normalization"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config, layer_idx: int):
        <span class="keyword">super</span>().__init__()
        <span class="comment"># TODO: Initialize attention layer</span>
        self.self_attn = <span class="todo">TODO</span>  <span class="comment"># Hint: GroupedQueryAttention(config, layer_idx)</span>
        
        <span class="comment"># TODO: Initialize FFN layer</span>
        self.mlp = <span class="todo">TODO</span>  <span class="comment"># Hint: Qwen3MLP(config)</span>
        
        <span class="comment"># TODO: Initialize normalization layers</span>
        self.input_layernorm = <span class="todo">TODO</span>  <span class="comment"># Hint: RMSNorm for before attention</span>
        self.post_attention_layernorm = <span class="todo">TODO</span>  <span class="comment"># Hint: RMSNorm for before FFN</span>
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, hidden_states, attention_mask=<span class="keyword">None</span>):
        <span class="comment"># TODO: Self-attention block with pre-norm and residual</span>
        <span class="comment"># Step 1: Save residual connection</span>
        residual = <span class="todo">TODO</span>
        
        <span class="comment"># Step 2: Apply normalization BEFORE attention</span>
        hidden_states = <span class="todo">TODO</span>  <span class="comment"># Hint: self.input_layernorm(hidden_states)</span>
        
        <span class="comment"># Step 3: Apply attention</span>
        hidden_states = <span class="todo">TODO</span>  <span class="comment"># Hint: self.self_attn(hidden_states, attention_mask)</span>
        
        <span class="comment"># Step 4: Add residual connection</span>
        hidden_states = <span class="todo">TODO</span>  <span class="comment"># Hint: residual + hidden_states</span>
        
        <span class="comment"># TODO: FFN block with pre-norm and residual (repeat pattern above)</span>
        <span class="comment"># Step 5-8: Same pattern but with post_attention_layernorm and mlp</span>
        <span class="keyword">pass</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('layer-hint-1')">💡 Hint 1: Component Initialization</button>
                    <button class="hint-button" onclick="showHint('layer-hint-2')">💡 Hint 2: Pre-Norm Pattern</button>
                    <button class="hint-button" onclick="showHint('layer-hint-3')">💡 Hint 3: Complete Forward Pass</button>
                    <button class="hint-button" onclick="showHint('layer-hint-4')">💡 Hint 4: Common Mistakes</button>
                    
                    <div id="layer-hint-1" class="hint-box">
                        <strong>🔧 Component Initialization:</strong>
                        <pre># In __init__ method:
self.self_attn = GroupedQueryAttention(config, layer_idx)
self.mlp = Qwen3MLP(config)
self.input_layernorm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
self.post_attention_layernorm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)</pre>
                        <p><strong>Key Points:</strong></p>
                        <ul>
                            <li>Pass layer_idx to attention for potential layer-specific behavior</li>
                            <li>Use config.rms_norm_eps for numerical stability</li>
                            <li>Both norms have the same dimension (hidden_size)</li>
                        </ul>
                    </div>
                    
                    <div id="layer-hint-2" class="hint-box">
                        <strong>🔄 Pre-Normalization Pattern:</strong>
                        <p>Remember: <strong>Norm → SubLayer → Residual</strong></p>
                        <pre># Attention block:
residual = hidden_states                          # Save original
hidden_states = self.input_layernorm(hidden_states)    # Norm first
hidden_states = self.self_attn(hidden_states, attention_mask)  # Then attention
hidden_states = residual + hidden_states         # Add back original

# FFN block (exact same pattern):
residual = hidden_states                          # Save current state
hidden_states = self.post_attention_layernorm(hidden_states)   # Norm first  
hidden_states = self.mlp(hidden_states)          # Then FFN
hidden_states = residual + hidden_states         # Add back</pre>
                    </div>
                    
                    <div id="layer-hint-3" class="hint-box">
                        <strong>✅ Complete Forward Pass:</strong>
                        <pre>def forward(self, hidden_states, attention_mask=None):
    # Self-attention with residual
    residual = hidden_states
    hidden_states = self.input_layernorm(hidden_states)
    hidden_states = self.self_attn(hidden_states, attention_mask)
    hidden_states = residual + hidden_states
    
    # FFN with residual
    residual = hidden_states
    hidden_states = self.post_attention_layernorm(hidden_states)
    hidden_states = self.mlp(hidden_states)
    hidden_states = residual + hidden_states
    
    return hidden_states</pre>
                        <p><strong>Notice:</strong> The exact same 4-step pattern is used twice!</p>
                    </div>
                    
                    <div id="layer-hint-4" class="hint-box">
                        <strong>🚨 Common Mistakes to Avoid:</strong>
                        <ul>
                            <li><strong>❌ Wrong order:</strong> Don't do sublayer → norm → residual</li>
                            <li><strong>❌ Missing residual:</strong> Always save the input before normalization</li>
                            <li><strong>❌ Norm dimensions:</strong> Both norms should be config.hidden_size</li>
                            <li><strong>❌ Forgetting attention_mask:</strong> Pass it to self_attn but not to mlp</li>
                            <li><strong>❌ Return forgotten:</strong> Don't forget to return hidden_states!</li>
                        </ul>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('layer-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="layer-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('layer-solution-code')">Copy</button>
                            <pre id="layer-solution-code"><span class="keyword">class</span> <span class="class-name">Qwen3DecoderLayer</span>(nn.Module):
    <span class="string">"""
    Single transformer layer in Qwen3.
    Uses pre-normalization and residual connections.
    """</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config, layer_idx: int):
        <span class="keyword">super</span>().__init__()
        self.self_attn = GroupedQueryAttention(config, layer_idx)
        self.mlp = Qwen3MLP(config)
        self.input_layernorm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        self.post_attention_layernorm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        
    <span class="keyword">def</span> <span class="function">forward</span>(self, hidden_states: torch.Tensor, 
                attention_mask: Optional[torch.Tensor] = <span class="keyword">None</span>) -> torch.Tensor:
        <span class="comment"># Self-attention with residual</span>
        residual = hidden_states
        hidden_states = self.input_layernorm(hidden_states)
        hidden_states = self.self_attn(hidden_states, attention_mask)
        hidden_states = residual + hidden_states
        
        <span class="comment"># FFN with residual</span>
        residual = hidden_states
        hidden_states = self.post_attention_layernorm(hidden_states)
        hidden_states = self.mlp(hidden_states)
        hidden_states = residual + hidden_states
        
        <span class="keyword">return</span> hidden_states</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 6: Complete Model -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 6: Complete Qwen3 Model</span>
                    <span class="difficulty hard">Hard</span>
                </div>
                
                <p>
                    Finally, let's assemble everything into a complete model! This is where all components come together.
                </p>
                
                <div class="concept-card">
                    <h4>🏛️ Complete Model Architecture</h4>
                    <p>The Qwen3Model is the base model that combines all components:</p>
                    
                    <div style="margin: 15px 0;">
                        <strong>📐 Model Flow:</strong>
                        <div class="code-block" style="margin: 10px 0;">
                            <pre style="font-size: 12px;">Input Token IDs
    ↓
Token Embeddings (vocab_size → hidden_size)
    ↓
Layer 1: [RMSNorm → Attention → Residual] → [RMSNorm → FFN → Residual]
    ↓
Layer 2: [RMSNorm → Attention → Residual] → [RMSNorm → FFN → Residual]
    ↓
... (num_hidden_layers total)
    ↓
Final RMSNorm
    ↓
Hidden States (ready for language modeling head)</pre>
                        </div>
                    </div>
                </div>
                
                <div class="learning-tip">
                    <strong>🧩 Key Components to Initialize:</strong>
                    <ol>
                        <li><strong>embed_tokens:</strong> nn.Embedding(vocab_size, hidden_size)</li>
                        <li><strong>layers:</strong> nn.ModuleList of Qwen3DecoderLayer instances</li>
                        <li><strong>norm:</strong> Final RMSNorm layer</li>
                        <li><strong>Weight initialization:</strong> Apply proper weight init (optional but good practice)</li>
                    </ol>
                </div>

                <div class="starter-code">
                    <pre><span class="keyword">class</span> <span class="class-name">Qwen3Model</span>(nn.Module):
    <span class="string">"""Base Qwen3 model without language modeling head"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config):
        <span class="keyword">super</span>().__init__()
        self.config = config
        
        <span class="comment"># TODO: Token embeddings</span>
        self.embed_tokens = <span class="todo">TODO</span>  <span class="comment"># Hint: nn.Embedding(config.vocab_size, config.hidden_size)</span>
        
        <span class="comment"># TODO: Transformer layers</span>
        self.layers = <span class="todo">TODO</span>  <span class="comment"># Hint: nn.ModuleList with num_hidden_layers</span>
        
        <span class="comment"># TODO: Final layer normalization</span>
        self.norm = <span class="todo">TODO</span>  <span class="comment"># Hint: RMSNorm(config.hidden_size, eps=config.rms_norm_eps)</span>
        
        <span class="comment"># TODO: Initialize weights (optional but recommended)</span>
        self.apply(self._init_weights)
        
    <span class="keyword">def</span> <span class="function">_init_weights</span>(self, module):
        <span class="comment"># TODO: Implement weight initialization</span>
        <span class="comment"># Hint: Standard normal init with std=0.02 for Linear and Embedding</span>
        <span class="keyword">pass</span>
            
    <span class="keyword">def</span> <span class="function">forward</span>(self, input_ids: torch.Tensor, attention_mask=<span class="keyword">None</span>):
        <span class="comment"># TODO: Step 1 - Embed tokens</span>
        hidden_states = <span class="todo">TODO</span>  <span class="comment"># Hint: self.embed_tokens(input_ids)</span>
        
        <span class="comment"># TODO: Step 2 - Create causal mask if needed</span>
        <span class="keyword">if</span> attention_mask <span class="keyword">is None</span>:
            <span class="comment"># Create upper triangular mask for autoregressive generation</span>
            batch_size, seq_len = input_ids.shape
            attention_mask = <span class="todo">TODO</span>  <span class="comment"># Hint: Use torch.triu to create causal mask</span>
        
        <span class="comment"># TODO: Step 3 - Pass through all transformer layers</span>
        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:
            hidden_states = <span class="todo">TODO</span>  <span class="comment"># Hint: layer(hidden_states, attention_mask)</span>
        
        <span class="comment"># TODO: Step 4 - Apply final normalization</span>
        hidden_states = <span class="todo">TODO</span>  <span class="comment"># Hint: self.norm(hidden_states)</span>
        
        <span class="keyword">return</span> hidden_states</pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('model-hint-1')">💡 Hint 1: Component Setup</button>
                    <button class="hint-button" onclick="showHint('model-hint-2')">💡 Hint 2: Causal Mask Creation</button>
                    <button class="hint-button" onclick="showHint('model-hint-3')">💡 Hint 3: Layer Loop</button>
                    <button class="hint-button" onclick="showHint('model-hint-4')">💡 Hint 4: Weight Initialization</button>
                    <button class="hint-button" onclick="showHint('model-hint-5')">💡 Hint 5: Adding Language Modeling Head</button>
                    
                    <div id="model-hint-1" class="hint-box">
                        <strong>🔧 Component Initialization:</strong>
                        <pre># Token embeddings
self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)

# Transformer layers
self.layers = nn.ModuleList([
    Qwen3DecoderLayer(config, idx) 
    for idx in range(config.num_hidden_layers)
])

# Final normalization
self.norm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)</pre>
                        <p><strong>Key Points:</strong></p>
                        <ul>
                            <li>Pass layer index to each decoder layer</li>
                            <li>Use nn.ModuleList so PyTorch tracks the layers properly</li>
                            <li>Final norm is same dimension as hidden_size</li>
                        </ul>
                    </div>
                    
                    <div id="model-hint-2" class="hint-box">
                        <strong>🎭 Causal Mask Creation:</strong>
                        <pre># Create causal attention mask
if attention_mask is None:
    batch_size, seq_len = input_ids.shape
    # Upper triangular matrix (1s above diagonal)
    attention_mask = torch.triu(
        torch.ones(seq_len, seq_len, device=input_ids.device), 
        diagonal=1
    )
    # Convert to -inf for masked positions
    attention_mask = attention_mask.masked_fill(
        attention_mask == 1, float('-inf')
    )
    # Add batch and head dimensions
    attention_mask = attention_mask.unsqueeze(0).unsqueeze(0)</pre>
                        <p><strong>Why:</strong> Prevents tokens from attending to future positions</p>
                    </div>
                    
                    <div id="model-hint-3" class="hint-box">
                        <strong>🔄 Layer Processing:</strong>
                        <pre># Simple but powerful pattern:
for layer in self.layers:
    hidden_states = layer(hidden_states, attention_mask)</pre>
                        <p><strong>That's it!</strong> Each layer takes hidden_states and returns transformed hidden_states.</p>
                        <p>The beauty of transformers: the same operation repeated N times!</p>
                    </div>
                    
                    <div id="model-hint-4" class="hint-box">
                        <strong>⚡ Weight Initialization:</strong>
                        <pre>def _init_weights(self, module):
    if isinstance(module, nn.Linear):
        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
        if module.bias is not None:
            torch.nn.init.zeros_(module.bias)
    elif isinstance(module, nn.Embedding):
        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)</pre>
                        <p><strong>Why 0.02 std?</strong> Standard practice from GPT paper - prevents vanishing/exploding gradients</p>
                    </div>
                    
                    <div id="model-hint-5" class="hint-box">
                        <strong>🎯 Adding Language Modeling Head:</strong>
                        <p>To make this a complete language model, you'll need Qwen3ForCausalLM:</p>
                        <pre>class Qwen3ForCausalLM(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.model = Qwen3Model(config)
        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)
    
    def forward(self, input_ids, labels=None):
        hidden_states = self.model(input_ids)
        logits = self.lm_head(hidden_states)
        
        loss = None
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))
        
        return logits, loss</pre>
                    </div>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('model-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="model-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('model-solution-code')">Copy</button>
                            <pre id="model-solution-code"><span class="keyword">class</span> <span class="class-name">Qwen3Model</span>(nn.Module):
    <span class="string">"""Base Qwen3 model without LM head"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config):
        <span class="keyword">super</span>().__init__()
        self.config = config
        
        <span class="comment"># Token embeddings</span>
        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)
        
        <span class="comment"># Transformer layers</span>
        self.layers = nn.ModuleList([
            Qwen3DecoderLayer(config, idx) 
            <span class="keyword">for</span> idx <span class="keyword">in</span> range(config.num_hidden_layers)
        ])
        
        <span class="comment"># Final layer norm</span>
        self.norm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        
        <span class="comment"># Initialize weights</span>
        self.apply(self._init_weights)
        
    <span class="keyword">def</span> <span class="function">_init_weights</span>(self, module):
        <span class="keyword">if</span> isinstance(module, nn.Linear):
            torch.nn.init.normal_(module.weight, mean=<span class="number">0.0</span>, std=<span class="number">0.02</span>)
        <span class="keyword">elif</span> isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, mean=<span class="number">0.0</span>, std=<span class="number">0.02</span>)
            
    <span class="keyword">def</span> <span class="function">forward</span>(self, input_ids: torch.Tensor, 
                attention_mask: Optional[torch.Tensor] = <span class="keyword">None</span>) -> torch.Tensor:
        <span class="comment"># Embed tokens</span>
        hidden_states = self.embed_tokens(input_ids)
        
        <span class="comment"># Create causal mask if needed</span>
        <span class="keyword">if</span> attention_mask <span class="keyword">is None</span>:
            batch_size, seq_len = input_ids.shape
            attention_mask = torch.triu(
                torch.ones(seq_len, seq_len, device=input_ids.device), 
                diagonal=<span class="number">1</span>
            ).masked_fill_(torch.ones(seq_len, seq_len) == <span class="number">1</span>, float(<span class="string">'-inf'</span>))
            attention_mask = attention_mask.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)
        
        <span class="comment"># Pass through transformer layers</span>
        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:
            hidden_states = layer(hidden_states, attention_mask)
        
        <span class="comment"># Apply final layer norm</span>
        hidden_states = self.norm(hidden_states)
        
        <span class="keyword">return</span> hidden_states

<span class="keyword">class</span> <span class="class-name">Qwen3ForCausalLM</span>(nn.Module):
    <span class="string">"""Qwen3 model with language modeling head"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, config: Qwen3Config):
        <span class="keyword">super</span>().__init__()
        self.model = Qwen3Model(config)
        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=<span class="keyword">False</span>)
        
        <span class="comment"># Tie embeddings if specified</span>
        <span class="keyword">if</span> config.tie_word_embeddings:
            self.lm_head.weight = self.model.embed_tokens.weight
            
    <span class="keyword">def</span> <span class="function">forward</span>(self, input_ids: torch.Tensor, labels: Optional[torch.Tensor] = <span class="keyword">None</span>):
        <span class="comment"># Get model outputs</span>
        hidden_states = self.model(input_ids)
        
        <span class="comment"># Project to vocabulary</span>
        logits = self.lm_head(hidden_states)
        
        <span class="comment"># Calculate loss if labels provided</span>
        loss = <span class="keyword">None</span>
        <span class="keyword">if</span> labels <span class="keyword">is not None</span>:
            shift_logits = logits[..., :-<span class="number">1</span>, :].contiguous()
            shift_labels = labels[..., <span class="number">1</span>:].contiguous()
            loss = F.cross_entropy(
                shift_logits.view(-<span class="number">1</span>, shift_logits.size(-<span class="number">1</span>)),
                shift_labels.view(-<span class="number">1</span>)
            )
        
        <span class="keyword">return</span> logits, loss
    
    <span class="keyword">def</span> <span class="function">generate</span>(self, input_ids: torch.Tensor, max_length: int = <span class="number">50</span>, 
                 temperature: float = <span class="number">0.8</span>, thinking_mode: bool = <span class="keyword">False</span>):
        <span class="string">"""Simple generation method with thinking mode support"""</span>
        self.eval()
        <span class="keyword">with</span> torch.no_grad():
            <span class="keyword">for</span> _ <span class="keyword">in</span> range(max_length):
                logits, _ = self.forward(input_ids)
                next_token_logits = logits[:, -<span class="number">1</span>, :] / temperature
                probs = F.softmax(next_token_logits, dim=-<span class="number">1</span>)
                next_token = torch.multinomial(probs, num_samples=<span class="number">1</span>)
                input_ids = torch.cat([input_ids, next_token], dim=<span class="number">1</span>)
                
                <span class="comment"># In real Qwen3, thinking mode would involve special tokens</span>
                <span class="comment"># and more complex generation logic</span>
                
        <span class="keyword">return</span> input_ids</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Challenge 7: Production Training & Inference -->
        <div class="section">
            <div class="challenge-box">
                <div class="challenge-header">
                    <span class="challenge-title">Challenge 7: Production Training & Inference</span>
                    <span class="difficulty hard">Hard</span>
                </div>
                
                <div class="concept-card">
                    <h4>🏭 Building Production-Ready Code</h4>
                    <p>Now it's time to put everything together! You'll create two scripts:</p>
                    <ul>
                        <li><strong>Training Script:</strong> Complete pipeline with AutoTokenizer, error handling, and checkpointing</li>
                        <li><strong>Inference Script:</strong> Load trained models and generate stories</li>
                        <li><strong>Production Features:</strong> Progress tracking, validation, sample generation during training</li>
                        <li><strong>Error Resilience:</strong> Handle common issues like OOM, tokenizer problems, etc.</li>
                    </ul>
                </div>
                
                <div class="learning-tip">
                    <strong>📊 What You'll Build:</strong>
                    <ul>
                        <li><strong>train_with_autotokenizer.py:</strong> Complete training pipeline</li>
                        <li><strong>inference.py:</strong> Interactive chat and story generation</li>
                        <li><strong>Key Features:</strong> AutoTokenizer, token clamping, progress bars, checkpointing</li>
                        <li><strong>Real Performance:</strong> Train a 43M parameter model in ~30 minutes</li>
                    </ul>
                </div>
                
                <h4>Part A: Production Training Script</h4>
                <p>Create a complete training script that handles real-world challenges and follows best practices.</p>
                
                <div class="starter-code">
                    <pre><span class="keyword">import</span> os
<span class="keyword">import</span> json
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader
<span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer  <span class="comment"># Qwen3 AutoTokenizer</span>

<span class="keyword">class</span> <span class="class-name">TinyStoriesDataset</span>(Dataset):
    <span class="string">"""Dataset for loading TinyStories JSON files"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, data_dir, tokenizer, max_length=<span class="number">512</span>, split=<span class="string">'train'</span>):
        <span class="comment"># TODO: Load JSON files and tokenize</span>
        <span class="keyword">pass</span>
    
    <span class="keyword">def</span> <span class="function">__len__</span>(self):
        <span class="comment"># TODO: Return dataset size</span>
        <span class="keyword">pass</span>
    
    <span class="keyword">def</span> <span class="function">__getitem__</span>(self, idx):
        <span class="comment"># TODO: Return tokenized story</span>
        <span class="keyword">pass</span>

<span class="comment"># Training loop structure</span>
<span class="keyword">def</span> <span class="function">train_qwen3_on_tinystories</span>(model, config, data_dir, num_epochs=<span class="number">3</span>):
    <span class="string">"""Complete training pipeline for TinyStories"""</span>
    <span class="comment"># TODO: Setup data, optimizer, and training loop</span>
    <span class="keyword">pass</span></pre>
                </div>
                
                <div class="hint-section">
                    <button class="hint-button" onclick="showHint('production-hint-1')">💡 Hint 1: Dataset Implementation</button>
                    <button class="hint-button" onclick="showHint('production-hint-2')">💡 Hint 2: Critical Production Fixes</button>
                    <button class="hint-button" onclick="showHint('production-hint-3')">💡 Hint 3: Complete Training Loop</button>
                    <button class="hint-button" onclick="showHint('production-hint-4')">💡 Hint 4: Inference & Generation</button>
                    <button class="hint-button" onclick="showHint('production-hint-5')">💡 Hint 5: Error Handling & Debugging</button>
                    
                    <div id="production-hint-1" class="hint-box">
                        <strong>🗃️ Complete Dataset Implementation:</strong>
                        <pre>def __init__(self, data_dir, tokenizer, max_length=512, split='train'):
    self.tokenizer = tokenizer
    self.max_length = max_length
    self.stories = []
    
    # Load JSON files with error handling
    json_pattern = os.path.join(data_dir, "tinystories/TinyStories_all_data/*.json")
    json_files = glob.glob(json_pattern)
    
    if not json_files:
        raise FileNotFoundError(f"No JSON files found at {json_pattern}")
    
    # Filter files based on split
    if split == 'train':
        json_files = [f for f in json_files if 'data00.json' not in f]
    else:
        json_files = [f for f in json_files if 'data00.json' in f]
        
    # Load stories with progress tracking
    for json_file in tqdm(json_files[:5], desc=f"Loading {split}"):
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
                for item in data:
                    if isinstance(item, dict) and 'story' in item:
                        story = item['story'].strip()
                        if len(story) > 10:
                            self.stories.append(story)
        except Exception as e:
            print(f"Error loading {json_file}: {e}")
            continue</pre>
                        <p><strong>Key Points:</strong> Progress tracking, error handling, proper file filtering</p>
                    </div>
                    
                    <div id="production-hint-2" class="hint-box">
                        <strong>🔧 Critical Production Fixes:</strong>
                        <div style="margin: 15px 0;">
                            <strong>1. Token Clamping (prevents IndexError):</strong>
                            <pre>input_ids = torch.clamp(input_ids, 0, tokenizer.vocab_size - 1)</pre>
                        </div>
                        <div style="margin: 15px 0;">
                            <strong>2. Fix Tokenizer Warnings:</strong>
                            <pre>os.environ["TOKENIZERS_PARALLELISM"] = "false"</pre>
                        </div>
                        <div style="margin: 15px 0;">
                            <strong>3. Fix Multiprocessing Issues:</strong>
                            <pre>DataLoader(..., num_workers=0)  # Critical for Jupyter/notebook users</pre>
                        </div>
                        <div style="margin: 15px 0;">
                            <strong>4. Update Config with Real Vocab Size:</strong>
                            <pre>config.vocab_size = tokenizer.vocab_size  # 151936 for Qwen3</pre>
                        </div>
                        <p><strong>These fixes resolve 90% of common training crashes!</strong></p>
                    </div>
                    
                    <div id="production-hint-3" class="hint-box">
                        <strong>🔄 Complete Training Loop:</strong>
                        <pre>for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    
    progress_bar = tqdm(train_dataloader, desc=f"Epoch {epoch + 1}")
    
    for batch_idx, input_ids in enumerate(progress_bar):
        input_ids = input_ids.to(device)
        
        # Create labels (same as input_ids for causal LM)
        labels = input_ids.clone()
        
        # Forward pass
        logits, loss = model(input_ids, labels=labels)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        # Update metrics
        epoch_loss += loss.item()
        progress_bar.set_postfix({'loss': f"{loss.item():.4f}"})
        
        # Generate samples during training
        if batch_idx % 100 == 0:
            sample = generate_sample(model, tokenizer, device)
            print(f"\\nStep {batch_idx} sample: {sample}")
    
    # Save checkpoint
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config,
        'tokenizer_name': "Qwen/Qwen3-8B"
    }, f"checkpoints/epoch_{epoch}.pth")</pre>
                    </div>
                    
                    <div id="production-hint-4" class="hint-box">
                        <strong>🎯 Inference & Generation:</strong>
                        <pre>def generate_sample(model, tokenizer, device, prompt="Once upon a time", max_length=100):
    model.eval()
    
    try:
        # Encode prompt
        inputs = tokenizer(prompt, return_tensors='pt').to(device)
        input_ids = inputs['input_ids']
        
        with torch.no_grad():
            generated = model.generate(input_ids, max_length=max_length, temperature=0.8)
            
        # Decode generated tokens
        generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)
        return generated_text
    except Exception as e:
        return f"Generation error: {e}"

# Interactive chat
def interactive_chat(model, tokenizer, device):
    print("🤖 Nano-Qwen3 Interactive Chat")
    print("Type 'quit' to exit")
    
    while True:
        user_input = input("\\nYou: ").strip()
        if user_input.lower() == 'quit':
            break
            
        story = generate_sample(model, tokenizer, device, user_input)
        print(f"Assistant: {story}")</pre>
                    </div>
                    
                    <div id="production-hint-5" class="hint-box">
                        <strong>🚨 Error Handling & Debugging:</strong>
                        <div style="margin: 15px 0;">
                            <strong>Common Issues & Solutions:</strong>
                            <ul>
                                <li><strong>IndexError with token IDs:</strong> Use torch.clamp() to fix</li>
                                <li><strong>Multiprocessing crashes:</strong> Set num_workers=0</li>
                                <li><strong>Tokenizer warnings:</strong> Set TOKENIZERS_PARALLELISM="false"</li>
                                <li><strong>CUDA OOM:</strong> Reduce batch_size or max_length</li>
                                <li><strong>No data found:</strong> Check tinystories/ directory exists</li>
                            </ul>
                        </div>
                        <div style="margin: 15px 0;">
                            <strong>Debugging Tips:</strong>
                            <pre># Check shapes and values
print(f"Input shape: {input_ids.shape}")
print(f"Token range: {input_ids.min()} to {input_ids.max()}")
print(f"Vocab size: {tokenizer.vocab_size}")

# Monitor memory
print(f"GPU memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")

# Test model forward pass
with torch.no_grad():
    test_output = model(input_ids[:1])  # Test with single sample</pre>
                        </div>
                    </div>
                </div>
                
                <h4>Part B: Inference Script Challenge</h4>
                <p>Now create a complete inference script that loads your trained model and provides multiple ways to generate stories.</p>
                
                <div class="starter-code">
                    <pre><span class="comment"># File: inference.py</span>
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F
<span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer
<span class="keyword">from</span> nano_qwen3 <span class="keyword">import</span> Qwen3ForCausalLM

<span class="keyword">def</span> <span class="function">load_trained_model</span>(checkpoint_path, device=<span class="string">'cpu'</span>):
    <span class="string">"""Load trained model from checkpoint"""</span>
    
    <span class="comment"># TODO: Load checkpoint safely</span>
    checkpoint = <span class="todo">torch.load(checkpoint_path, map_location=device)</span>
    config = checkpoint[<span class="string">'config'</span>]
    
    <span class="comment"># TODO: Initialize model and load weights</span>
    model = <span class="todo">Qwen3ForCausalLM(config)</span>
    model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])
    model = model.to(device).eval()
    
    <span class="comment"># TODO: Load tokenizer</span>
    tokenizer = <span class="todo">AutoTokenizer.from_pretrained('Qwen/Qwen3-8B')</span>
    <span class="keyword">if</span> tokenizer.pad_token <span class="keyword">is None</span>:
        tokenizer.pad_token = tokenizer.eos_token
    
    <span class="keyword">return</span> model, tokenizer, config

<span class="keyword">def</span> <span class="function">generate_text</span>(model, tokenizer, prompt, max_length=<span class="number">100</span>, temperature=<span class="number">0.8</span>, device=<span class="string">'cpu'</span>):
    <span class="string">"""Generate text with advanced sampling"""</span>
    
    <span class="comment"># TODO: Tokenize prompt</span>
    inputs = tokenizer(prompt, return_tensors=<span class="string">'pt'</span>).to(device)
    input_ids = inputs[<span class="string">'input_ids'</span>]
    
    <span class="keyword">with</span> torch.no_grad():
        generated_ids = input_ids.clone()
        
        <span class="comment"># TODO: Implement generation loop</span>
        <span class="keyword">for</span> step <span class="keyword">in</span> range(max_length - input_ids.shape[<span class="number">1</span>]):
            <span class="comment"># TODO: Forward pass to get next token logits</span>
            outputs = <span class="todo">model.model(generated_ids)</span>
            
            <span class="comment"># TODO: Get logits for next token</span>
            logits = model.lm_head(outputs) <span class="keyword">if</span> model.lm_head <span class="keyword">else</span> F.linear(outputs, model.model.embed_tokens.weight)
            next_token_logits = logits[:, -<span class="number">1</span>, :] / temperature
            
            <span class="comment"># TODO: Sample next token</span>
            probs = F.softmax(next_token_logits, dim=-<span class="number">1</span>)
            next_token = <span class="todo">torch.multinomial(probs, 1)</span>
            
            <span class="comment"># TODO: Add to sequence and check for EOS</span>
            generated_ids = torch.cat([generated_ids, next_token], dim=<span class="number">1</span>)
            <span class="keyword">if</span> next_token.item() == tokenizer.eos_token_id:
                <span class="keyword">break</span>
    
    <span class="comment"># TODO: Decode final result</span>
    generated_text = <span class="todo">tokenizer.decode(generated_ids[0], skip_special_tokens=True)</span>
    <span class="keyword">return</span> generated_text

<span class="keyword">def</span> <span class="function">interactive_chat</span>(model, tokenizer, config, device=<span class="string">'cpu'</span>):
    <span class="string">"""Interactive chat interface"""</span>
    
    print(<span class="string">"\\n🤖 Nano-Qwen3 Interactive Chat"</span>)
    print(<span class="string">"Type 'quit' to exit, 'clear' to reset"</span>)
    print(<span class="string">"Settings: temp=0.8, max_len=200"</span>)
    print(<span class="string">"-" * 50</span>)
    
    conversation_history = <span class="string">""</span>
    
    <span class="keyword">while</span> <span class="keyword">True</span>:
        <span class="keyword">try</span>:
            user_input = input(<span class="string">"\\nYou: "</span>).strip()
            
            <span class="keyword">if</span> user_input.lower() == <span class="string">'quit'</span>:
                print(<span class="string">"Goodbye! 👋"</span>)
                <span class="keyword">break</span>
            <span class="keyword">elif</span> user_input.lower() == <span class="string">'clear'</span>:
                conversation_history = <span class="string">""</span>
                print(<span class="string">"Conversation cleared!"</span>)
                <span class="keyword">continue</span>
            
            <span class="comment"># TODO: Build prompt with history</span>
            prompt = <span class="todo">f"{conversation_history}\\nHuman: {user_input}\\nAssistant:" if conversation_history else f"Human: {user_input}\\nAssistant:"</span>
            
            <span class="comment"># TODO: Generate response</span>
            generated = generate_text(model, tokenizer, prompt, max_length=<span class="number">200</span>, device=device)
            
            <span class="comment"># TODO: Extract assistant response</span>
            <span class="keyword">if</span> <span class="string">"Assistant:"</span> <span class="keyword">in</span> generated:
                assistant_response = generated.split(<span class="string">"Assistant:"</span>)[-<span class="number">1</span>].strip()
            <span class="keyword">else</span>:
                assistant_response = generated[len(prompt):].strip()[:<span class="number">200</span>]
            
            print(<span class="string">f"\\nAssistant: {assistant_response}"</span>)
            
            <span class="comment"># TODO: Update conversation history</span>
            conversation_history = <span class="string">f"{conversation_history}\\nHuman: {user_input}\\nAssistant: {assistant_response}"</span>
            
        <span class="keyword">except</span> KeyboardInterrupt:
            print(<span class="string">"\\n\\nGoodbye! 👋"</span>)
            <span class="keyword">break</span>

<span class="keyword">def</span> <span class="function">run_story_generation</span>(model, tokenizer, device=<span class="string">'cpu'</span>):
    <span class="string">"""Generate sample stories with different prompts"""</span>
    
    story_prompts = [
        <span class="string">"Once upon a time, there was a little girl named"</span>,
        <span class="string">"In a magical forest, a brave knight discovered"</span>,
        <span class="string">"The friendly dragon lived in a castle where"</span>,
        <span class="string">"Every morning, the cat would wake up and"</span>,
    ]
    
    print(<span class="string">"\\n📚 Story Generation Samples"</span>)
    print(<span class="string">"-" * 50</span>)
    
    <span class="keyword">for</span> i, prompt <span class="keyword">in</span> enumerate(story_prompts, <span class="number">1</span>):
        print(<span class="string">f"\\n--- Story {i} ---"</span>)
        
        <span class="comment"># TODO: Generate story</span>
        generated = generate_text(model, tokenizer, prompt, max_length=<span class="number">150</span>, temperature=<span class="number">0.9</span>, device=device)
        
        print(<span class="string">f"Prompt: {prompt}"</span>)
        print(<span class="string">f"Story: {generated}"</span>)

<span class="comment"># TODO: Main function that ties everything together</span>
<span class="keyword">def</span> <span class="function">main</span>():
    <span class="string">"""Main inference function with user menu"""</span>
    
    <span class="comment"># TODO: Setup device</span>
    device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)
    print(<span class="string">f"Using device: {device}"</span>)
    
    <span class="comment"># TODO: Load model</span>
    checkpoint_path = input(<span class="string">"Enter checkpoint path (or press Enter for 'checkpoints/best_model.pth'): "</span>).strip()
    <span class="keyword">if</span> <span class="keyword">not</span> checkpoint_path:
        checkpoint_path = <span class="string">"checkpoints/best_model.pth"</span>
    
    <span class="keyword">try</span>:
        model, tokenizer, config = load_trained_model(checkpoint_path, device)
        print(<span class="string">"✅ Model loaded successfully!"</span>)
    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:
        print(<span class="string">f"❌ Error loading model: {e}"</span>)
        <span class="keyword">return</span>
    
    <span class="comment"># TODO: Provide menu options</span>
    print(<span class="string">"\\nSelect mode:"</span>)
    print(<span class="string">"1. Interactive chat"</span>)
    print(<span class="string">"2. Story generation samples"</span>)
    print(<span class="string">"3. Single prompt"</span>)
    
    choice = input(<span class="string">"Enter choice (1-3): "</span>).strip()
    
    <span class="keyword">if</span> choice == <span class="string">'1'</span>:
        interactive_chat(model, tokenizer, config, device)
    <span class="keyword">elif</span> choice == <span class="string">'2'</span>:
        run_story_generation(model, tokenizer, device)
    <span class="keyword">elif</span> choice == <span class="string">'3'</span>:
        prompt = input(<span class="string">"Enter your prompt: "</span>).strip()
        <span class="keyword">if</span> prompt:
            generated = generate_text(model, tokenizer, prompt, max_length=<span class="number">200</span>, device=device)
            print(<span class="string">f"\\nPrompt: {prompt}"</span>)
            print(<span class="string">f"Generated: {generated}"</span>)
    <span class="keyword">else</span>:
        print(<span class="string">"Invalid choice!"</span>)

<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:
    main()</pre>
                </div>
                
                <div class="learning-tip">
                    <strong>🎯 Inference Features to Implement:</strong>
                    <ul>
                        <li><strong>Model Loading:</strong> Safe checkpoint loading with error handling</li>
                        <li><strong>Text Generation:</strong> Custom generation loop with temperature control</li>
                        <li><strong>Interactive Chat:</strong> Conversation history and context management</li>
                        <li><strong>Story Samples:</strong> Batch generation with different prompts</li>
                        <li><strong>Menu System:</strong> User-friendly interface for different modes</li>
                    </ul>
                </div>
                
                <div class="solution-section">
                    <button class="solution-toggle" onclick="toggleSolution('training-solution')">
                        <span>🔓</span>
                        <span>Show Solution</span>
                    </button>
                    
                    <div id="training-solution" class="solution-content">
                        <div class="code-block">
                            <button class="copy-button" onclick="copyCode('training-solution-code')">Copy</button>
                            <pre id="training-solution-code"><span class="keyword">import</span> os
<span class="keyword">import</span> json
<span class="keyword">import</span> glob
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn
<span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim
<span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm
<span class="keyword">import</span> time
<span class="keyword">from</span> tokenizer <span class="keyword">import</span> Tokenizer

<span class="keyword">class</span> <span class="class-name">TinyStoriesDataset</span>(Dataset):
    <span class="string">"""Dataset for loading TinyStories JSON files"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, data_dir, tokenizer, max_length=<span class="number">512</span>, split=<span class="string">'train'</span>):
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.stories = []
        
        <span class="comment"># Load stories from JSON files</span>
        json_pattern = os.path.join(data_dir, <span class="string">"TinyStories_all_data/*.json"</span>)
        json_files = glob.glob(json_pattern)
        
        <span class="keyword">if</span> split == <span class="string">'train'</span>:
            <span class="comment"># Use files 01-49 for training (shard 00 is validation)</span>
            json_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> json_files <span class="keyword">if</span> <span class="string">'data00.json'</span> <span class="keyword">not in</span> f]
        <span class="keyword">else</span>:
            <span class="comment"># Use shard 00 for validation</span>
            json_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> json_files <span class="keyword">if</span> <span class="string">'data00.json'</span> <span class="keyword">in</span> f]
            
        print(<span class="string">f"Loading {split} data from {len(json_files)} files..."</span>)
        
        <span class="keyword">for</span> json_file <span class="keyword">in</span> tqdm(json_files[:<span class="number">5</span>]):  <span class="comment"># Limit to 5 files for demo</span>
            <span class="keyword">with</span> open(json_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:
                data = json.load(f)
                <span class="keyword">for</span> item <span class="keyword">in</span> data:
                    story = item[<span class="string">'story'</span>].strip()
                    <span class="keyword">if</span> len(story) > <span class="number">10</span>:  <span class="comment"># Filter very short stories</span>
                        self.stories.append(story)
        
        print(<span class="string">f"Loaded {len(self.stories)} stories for {split}"</span>)
        
    <span class="keyword">def</span> <span class="function">__len__</span>(self):
        <span class="keyword">return</span> len(self.stories)
    
    <span class="keyword">def</span> <span class="function">__getitem__</span>(self, idx):
        story = self.stories[idx]
        
        <span class="comment"># Tokenize with BOS and EOS</span>
        tokens = self.tokenizer.encode(story, bos=<span class="keyword">True</span>, eos=<span class="keyword">True</span>)
        
        <span class="comment"># Truncate or pad to max_length</span>
        <span class="keyword">if</span> len(tokens) > self.max_length:
            tokens = tokens[:self.max_length]
        <span class="keyword">else</span>:
            <span class="comment"># Pad with a special pad token (we'll use 0)</span>
            tokens = tokens + [<span class="number">0</span>] * (self.max_length - len(tokens))
            
        <span class="keyword">return</span> torch.tensor(tokens, dtype=torch.long)

<span class="keyword">def</span> <span class="function">create_attention_mask</span>(input_ids, pad_token_id=<span class="number">0</span>):
    <span class="string">"""Create attention mask to ignore padding tokens"""</span>
    <span class="keyword">return</span> (input_ids != pad_token_id).float()

<span class="keyword">def</span> <span class="function">evaluate_model</span>(model, val_dataloader, device):
    <span class="string">"""Evaluate model on validation set"""</span>
    model.eval()
    total_loss = <span class="number">0</span>
    total_tokens = <span class="number">0</span>
    
    <span class="keyword">with</span> torch.no_grad():
        <span class="keyword">for</span> batch <span class="keyword">in</span> val_dataloader:
            input_ids = batch.to(device)
            attention_mask = create_attention_mask(input_ids).to(device)
            
            <span class="comment"># Create labels (same as input_ids for causal LM)</span>
            labels = input_ids.clone()
            
            <span class="comment"># Forward pass</span>
            logits, loss = model(input_ids, labels=labels)
            
            <span class="comment"># Only count non-padding tokens</span>
            mask = attention_mask.view(-<span class="number">1</span>)
            total_loss += loss.item() * mask.sum().item()
            total_tokens += mask.sum().item()
    
    avg_loss = total_loss / total_tokens <span class="keyword">if</span> total_tokens > <span class="number">0</span> <span class="keyword">else</span> float(<span class="string">'inf'</span>)
    perplexity = torch.exp(torch.tensor(avg_loss))
    
    <span class="keyword">return</span> avg_loss, perplexity.item()

<span class="keyword">def</span> <span class="function">generate_sample</span>(model, tokenizer, device, prompt=<span class="string">"Once upon a time"</span>, max_length=<span class="number">100</span>):
    <span class="string">"""Generate a sample story"""</span>
    model.eval()
    
    <span class="comment"># Encode prompt</span>
    input_ids = torch.tensor([tokenizer.encode(prompt, bos=<span class="keyword">True</span>, eos=<span class="keyword">False</span>)]).to(device)
    
    <span class="keyword">with</span> torch.no_grad():
        generated = model.generate(input_ids, max_length=max_length, temperature=<span class="number">0.8</span>)
        
    <span class="comment"># Decode generated tokens</span>
    generated_text = tokenizer.decode(generated[<span class="number">0</span>].tolist())
    <span class="keyword">return</span> generated_text

<span class="keyword">def</span> <span class="function">train_qwen3_on_tinystories</span>(config, data_dir, num_epochs=<span class="number">3</span>, batch_size=<span class="number">8</span>, 
                                learning_rate=<span class="number">1e-4</span>, save_dir=<span class="string">"./checkpoints"</span>):
    <span class="string">"""
    Complete training pipeline for Qwen3 on TinyStories
    """</span>
    <span class="comment"># Setup device</span>
    device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)
    print(<span class="string">f"Training on device: {device}"</span>)
    
    <span class="comment"># Initialize AutoTokenizer (no local files needed!)</span>
    <span class="keyword">import</span> os
    os.environ[<span class="string">"TOKENIZERS_PARALLELISM"</span>] = <span class="string">"false"</span>  <span class="comment"># Fix warnings</span>
    
    tokenizer = AutoTokenizer.from_pretrained(<span class="string">"Qwen/Qwen3-8B"</span>)
    <span class="keyword">if</span> tokenizer.pad_token <span class="keyword">is</span> <span class="keyword">None</span>:
        tokenizer.pad_token = tokenizer.eos_token
    
    <span class="comment"># Create datasets</span>
    train_dataset = TinyStoriesDataset(data_dir, tokenizer, max_length=config.max_position_embeddings, split=<span class="string">'train'</span>)
    val_dataset = TinyStoriesDataset(data_dir, tokenizer, max_length=config.max_position_embeddings, split=<span class="string">'val'</span>)
    
    <span class="comment"># Create data loaders</span>
    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">2</span>)
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="keyword">False</span>, num_workers=<span class="number">2</span>)
    
    <span class="comment"># Initialize model</span>
    model = Qwen3ForCausalLM(config).to(device)
    
    <span class="comment"># Count parameters</span>
    total_params = sum(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())
    trainable_params = sum(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)
    
    print(<span class="string">f"Total parameters: {total_params:,}"</span>)
    print(<span class="string">f"Trainable parameters: {trainable_params:,}"</span>)
    print(<span class="string">f"Model size: {total_params * 4 / 1024**2:.2f} MB (float32)"</span>)
    
    <span class="comment"># Setup optimizer and scheduler</span>
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=<span class="number">0.01</span>)
    
    total_steps = len(train_dataloader) * num_epochs
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)
    
    <span class="comment"># Create save directory</span>
    os.makedirs(save_dir, exist_ok=<span class="keyword">True</span>)
    
    <span class="comment"># Training loop</span>
    model.train()
    global_step = <span class="number">0</span>
    best_val_loss = float(<span class="string">'inf'</span>)
    
    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):
        print(<span class="string">f"\n=== Epoch {epoch + 1}/{num_epochs} ==="</span>)
        
        epoch_loss = <span class="number">0</span>
        epoch_steps = <span class="number">0</span>
        start_time = time.time()
        
        progress_bar = tqdm(train_dataloader, desc=<span class="string">f"Epoch {epoch + 1}"</span>)
        
        <span class="keyword">for</span> batch_idx, input_ids <span class="keyword">in</span> enumerate(progress_bar):
            input_ids = input_ids.to(device)
            attention_mask = create_attention_mask(input_ids).to(device)
            
            <span class="comment"># Create labels (same as input_ids for causal language modeling)</span>
            labels = input_ids.clone()
            
            <span class="comment"># Forward pass</span>
            logits, loss = model(input_ids, labels=labels)
            
            <span class="comment"># Backward pass</span>
            optimizer.zero_grad()
            loss.backward()
            
            <span class="comment"># Gradient clipping for stability</span>
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)
            
            optimizer.step()
            scheduler.step()
            
            <span class="comment"># Update metrics</span>
            epoch_loss += loss.item()
            epoch_steps += <span class="number">1</span>
            global_step += <span class="number">1</span>
            
            <span class="comment"># Update progress bar</span>
            progress_bar.set_postfix({
                <span class="string">'loss'</span>: <span class="string">f"{loss.item():.4f}"</span>,
                <span class="string">'avg_loss'</span>: <span class="string">f"{epoch_loss / epoch_steps:.4f}"</span>,
                <span class="string">'lr'</span>: <span class="string">f"{scheduler.get_last_lr()[0]:.2e}"</span>
            })
            
            <span class="comment"># Log and save periodically</span>
            <span class="keyword">if</span> global_step % <span class="number">500</span> == <span class="number">0</span>:
                <span class="comment"># Generate sample</span>
                sample_text = generate_sample(model, tokenizer, device)
                print(<span class="string">f"\nStep {global_step} sample: {sample_text}"</span>)
                model.train()  <span class="comment"># Back to training mode</span>
        
        <span class="comment"># End of epoch evaluation</span>
        avg_train_loss = epoch_loss / epoch_steps
        val_loss, val_perplexity = evaluate_model(model, val_dataloader, device)
        
        epoch_time = time.time() - start_time
        
        print(<span class="string">f"\nEpoch {epoch + 1} Summary:"</span>)
        print(<span class="string">f"  Training Loss: {avg_train_loss:.4f}"</span>)
        print(<span class="string">f"  Validation Loss: {val_loss:.4f}"</span>)
        print(<span class="string">f"  Validation Perplexity: {val_perplexity:.2f}"</span>)
        print(<span class="string">f"  Time: {epoch_time:.2f}s"</span>)
        
        <span class="comment"># Save checkpoint</span>
        checkpoint = {
            <span class="string">'epoch'</span>: epoch + <span class="number">1</span>,
            <span class="string">'model_state_dict'</span>: model.state_dict(),
            <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),
            <span class="string">'scheduler_state_dict'</span>: scheduler.state_dict(),
            <span class="string">'train_loss'</span>: avg_train_loss,
            <span class="string">'val_loss'</span>: val_loss,
            <span class="string">'config'</span>: config,
            <span class="string">'global_step'</span>: global_step
        }
        
        <span class="comment"># Save latest checkpoint</span>
        torch.save(checkpoint, os.path.join(save_dir, <span class="string">'latest_checkpoint.pth'</span>))
        
        <span class="comment"># Save best model</span>
        <span class="keyword">if</span> val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(checkpoint, os.path.join(save_dir, <span class="string">'best_model.pth'</span>))
            print(<span class="string">"  ✓ New best model saved!"</span>)
        
        model.train()  <span class="comment"># Back to training mode</span>
    
    print(<span class="string">f"\n🎉 Training completed!"</span>)
    print(<span class="string">f"Best validation loss: {best_val_loss:.4f}"</span>)
    
    <span class="comment"># Generate final samples</span>
    print(<span class="string">"\n=== Final Generation Samples ==="</span>)
    <span class="keyword">for</span> prompt <span class="keyword">in</span> [<span class="string">"Once upon a time"</span>, <span class="string">"The little girl"</span>, <span class="string">"In a magical forest"</span>]:
        sample = generate_sample(model, tokenizer, device, prompt=prompt)
        print(<span class="string">f"\nPrompt: {prompt}"</span>)
        print(<span class="string">f"Generated: {sample}"</span>)
    
    <span class="keyword">return</span> model

<span class="comment"># Example usage</span>
<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:
    <span class="comment"># Create configuration</span>
    config = Qwen3Config()
    
    <span class="comment"># Train model (adjust data_dir to your tinystories folder)</span>
    data_dir = <span class="string">"./tinystories"</span>
    trained_model = train_qwen3_on_tinystories(
        config=config,
        data_dir=data_dir,
        num_epochs=<span class="number">3</span>,
        batch_size=<span class="number">8</span>,
        learning_rate=<span class="number">1e-4</span>
    )</pre>
                        </div>
                        
                        <div class="concept-card">
                            <h4>🔍 Understanding the Training Process</h4>
                            <div style="margin: 15px 0;">
                                <strong>📊 What to Watch During Training:</strong>
                                <ul>
                                    <li><strong>Loss Curve:</strong> Should decrease from ~8.0 to ~3.5-4.0</li>
                                    <li><strong>Perplexity:</strong> Lower is better (good models: 20-50)</li>
                                    <li><strong>Generated Samples:</strong> Should become more coherent over time</li>
                                    <li><strong>Learning Rate:</strong> Decreases with cosine schedule</li>
                                </ul>
                            </div>
                            
                            <div style="margin: 15px 0;">
                                <strong>⚡ Performance Expectations:</strong>
                                <ul>
                                    <li><strong>First epoch:</strong> Random text → simple words</li>
                                    <li><strong>Second epoch:</strong> Basic sentences emerge</li>
                                    <li><strong>Third epoch:</strong> Coherent short stories</li>
                                    <li><strong>Memory usage:</strong> ~2-4GB VRAM with batch_size=8</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="learning-tip">
                            <strong>🚀 Quick Start Commands:</strong>
                            <div class="code-block" style="margin: 10px 0;">
                                <pre style="font-size: 12px;"># 1. First, run the data preparation
python tiny_stories.py  # Downloads and tokenizes TinyStories

# 2. Then train your model
python qwen3_training.py  # Uses the code above

# 3. Monitor training
# Watch the loss decrease and samples improve!
# Best models saved to ./checkpoints/best_model.pth</pre>
                            </div>
                        </div>
                        
                        <div class="concept-card">
                            <h4>🔧 Troubleshooting Training Issues</h4>
                            <div style="margin: 15px 0;">
                                <strong>❌ "Unable to load tokenizer"</strong>
                                <ul>
                                    <li>Ensure internet connection (AutoTokenizer downloads automatically)</li>
                                    <li>Install transformers: pip install transformers</li>
                                    <li>Set environment: os.environ["TOKENIZERS_PARALLELISM"] = "false"</li>
                                </ul>
                            </div>
                            
                            <div style="margin: 15px 0;">
                                <strong>❌ "CUDA out of memory"</strong>
                                <ul>
                                    <li>Reduce batch_size from 8 to 4 or 2</li>
                                    <li>Reduce max_length from 512 to 256</li>
                                    <li>Use CPU training (slower but works): device="cpu"</li>
                                </ul>
                            </div>
                            
                            <div style="margin: 15px 0;">
                                <strong>❌ "Loss not decreasing"</strong>
                                <ul>
                                    <li>Check learning rate (try 5e-5 or 2e-4)</li>
                                    <li>Verify data loading is correct</li>
                                    <li>Enable QK normalization in config</li>
                                    <li>Increase gradient clipping to 0.5</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- PyTorch Quick Reference -->
        <div class="section">
            <h2>🔥 PyTorch Quick Reference</h2>
            
            <div class="concept-card">
                <h3>📋 Essential Operations Cheat Sheet</h3>
                <p>Quick reference for the PyTorch operations used in this tutorial:</p>
                
                <div style="margin: 15px 0;">
                    <strong>🔧 Tensor Creation & Info:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 11px;">torch.randn(2, 3, 4)           # Random normal tensor
torch.ones(384)                # All ones
torch.zeros_like(x)            # Same shape as x, filled with zeros
x.shape                        # Get dimensions: torch.Size([2, 3, 4])
x.dtype                        # Data type: torch.float32
x.device                       # Device: cpu or cuda:0</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>🔄 Shape Operations:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 11px;">x.view(2, -1)                  # Reshape (-1 = auto-calculate)
x.transpose(1, 2)              # Swap dimensions 1 and 2
x.unsqueeze(0)                 # Add dimension at index 0
x.squeeze()                    # Remove all size-1 dimensions
x.reshape(2, 6)                # Same as view but more flexible</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>🧮 Math Operations:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 11px;">x.pow(2)                       # Square each element
x.sqrt()                       # Square root
torch.rsqrt(x)                 # 1/√x (reciprocal square root)
x.mean(dim=-1, keepdim=True)   # Mean along last dim, keep shape
torch.matmul(a, b)             # Matrix multiplication
x * y                          # Element-wise multiplication</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>🎯 Attention-Specific:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 11px;">F.softmax(x, dim=-1)           # Convert to probabilities
F.dropout(x, p=0.1, training=True)  # Randomly zero elements
torch.triu(x, diagonal=1)      # Upper triangular matrix
x.masked_fill(mask, value)     # Replace masked positions with value
torch.einsum('ij,jk->ik', a, b)  # Einstein summation (advanced)</pre>
                    </div>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>🏗️ Neural Network Components:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 11px;">nn.Linear(in_features, out_features, bias=False)
nn.Parameter(torch.ones(384))  # Learnable parameter
nn.ModuleList([layer1, layer2])  # List of modules
self.register_buffer('name', tensor)  # Non-learnable tensor</pre>
                    </div>
                </div>
            </div>
            
            <div class="concept-card">
                <h3>🐛 Common PyTorch Gotchas</h3>
                
                <div style="margin: 15px 0;">
                    <strong>❌ Common Mistakes:</strong>
                    <ul>
                        <li><strong>Shape mismatch:</strong> Always check tensor shapes with .shape</li>
                        <li><strong>In-place operations:</strong> Be careful with operations like +=, they can break gradients</li>
                        <li><strong>Device mismatch:</strong> All tensors in an operation must be on same device</li>
                        <li><strong>Gradient issues:</strong> Use torch.no_grad() for inference</li>
                    </ul>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>✅ Debug Like a Pro:</strong>
                    <div class="code-block" style="margin: 10px 0;">
                        <pre style="font-size: 11px;"># Always print shapes when debugging
print(f"queries: {queries.shape}")
print(f"keys: {keys.shape}")

# Check for NaN or inf values
print(f"Has NaN: {torch.isnan(x).any()}")
print(f"Has inf: {torch.isinf(x).any()}")

# Inspect a few values
print(f"Sample values: {x[0, 0, :5]}")</pre>
                    </div>
                </div>
            </div>
            
            <div class="learning-tip">
                <strong>💡 Pro Tips:</strong>
                <ul>
                    <li><strong>Start small:</strong> Test with tiny tensors first (batch=1, seq=5)</li>
                    <li><strong>Print everything:</strong> When debugging, print shapes and values liberally</li>
                    <li><strong>Use .contiguous():</strong> If you get "tensor not contiguous" errors</li>
                    <li><strong>GPU memory:</strong> Use .cpu() to move tensors back for inspection</li>
                </ul>
            </div>
        </div>
        
        <!-- Debugging Section -->
        <div class="section">
            <h2>🐛 Debugging & Troubleshooting</h2>
            
            <div class="concept-card">
                <h3>🔧 Common Issues & Solutions</h3>
                
                <div style="margin: 15px 0;">
                    <strong>❌ "RuntimeError: mat1 and mat2 shapes cannot be multiplied"</strong>
                    <ul>
                        <li><strong>Problem:</strong> Dimension mismatch in linear layers</li>
                        <li><strong>Solution:</strong> Check that hidden_size divides evenly by num_attention_heads</li>
                        <li><strong>Example:</strong> hidden_size=384, num_heads=6 → head_dim=64 ✅</li>
                    </ul>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>❌ "CUDA out of memory"</strong>
                    <ul>
                        <li><strong>Problem:</strong> Model too large for GPU</li>
                        <li><strong>Solution:</strong> Reduce batch_size or use CPU: model.to('cpu')</li>
                        <li><strong>Alternative:</strong> Use smaller hidden_size (256 instead of 384)</li>
                    </ul>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>❌ "Loss is NaN or exploding"</strong>
                    <ul>
                        <li><strong>Problem:</strong> Gradient explosion</li>
                        <li><strong>Solution:</strong> Enable QK normalization, use gradient clipping</li>
                        <li><strong>Code:</strong> torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)</li>
                    </ul>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>❌ "Model generates repetitive text"</strong>
                    <ul>
                        <li><strong>Problem:</strong> Poor attention patterns or undertrained</li>
                        <li><strong>Solution:</strong> Train longer, adjust temperature in generation</li>
                        <li><strong>Try:</strong> temperature=0.8 for more creative, temperature=0.3 for focused</li>
                    </ul>
                </div>
            </div>
            
            <div class="learning-tip">
                <strong>🔍 Debugging Tips:</strong>
                <ul>
                    <li><strong>Print Shapes:</strong> Add print(x.shape) to track tensor dimensions</li>
                    <li><strong>Check Gradients:</strong> Use model.named_parameters() to inspect grad norms</li>
                    <li><strong>Validate Config:</strong> Ensure all dimensions are compatible</li>
                    <li><strong>Start Small:</strong> Test with tiny models first (hidden_size=64)</li>
                </ul>
            </div>
            
            <div class="code-block">
                <button class="copy-button" onclick="copyCode('debug-code')">Copy</button>
                <pre id="debug-code"># Quick debugging helper
def debug_model(model, input_ids):
    """Print model info for debugging"""
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Input shape: {input_ids.shape}")
    
    # Forward pass with shape tracking
    with torch.no_grad():
        try:
            output = model(input_ids)
            print(f"Output shape: {output[0].shape if isinstance(output, tuple) else output.shape}")
            print("✅ Forward pass successful!")
        except Exception as e:
            print(f"❌ Error: {e}")
            
    # Check for NaN parameters
    nan_params = [name for name, param in model.named_parameters() if torch.isnan(param).any()]
    if nan_params:
        print(f"⚠️ NaN parameters found: {nan_params}")
    else:
        print("✅ No NaN parameters")

# Usage
config = Qwen3Config()
model = Qwen3ForCausalLM(config)
test_input = torch.randint(0, config.vocab_size, (1, 10))
debug_model(model, test_input)</pre>
            </div>
        </div>
        
        <!-- File Organization Section -->
        <div class="section">
            <h2>📁 Production File Structure</h2>
            <p>
                For real projects, it's best to separate training and inference code. Here's the recommended structure:
            </p>
            
            <div class="concept-card">
                <h3>🏗️ Recommended File Organization</h3>
                <div class="code-block">
                    <pre>nano-qwen3/
├── nano_qwen3.py          # Core model classes (Qwen3Config, Qwen3ForCausalLM, etc.)
├── train_with_autotokenizer.py  # Training script with AutoTokenizer
├── inference.py           # Full inference with interactive chat and story generation
├── quick_inference.py     # Simple test script for quick model validation
├── tiny_stories.py        # Dataset download and preprocessing
├── checkpoints/           # Saved model checkpoints
│   ├── best_model.pth
│   └── latest_checkpoint.pth
├── tinystories/           # Downloaded dataset
└── qwen3-toy-model-tutorial.html  # This tutorial!</pre>
                </div>
            </div>
            
            <div class="learning-tip">
                <strong>📋 File Purposes:</strong>
                <ul>
                    <li><strong>nano_qwen3.py:</strong> Contains all model classes and architecture</li>
                    <li><strong>train_with_autotokenizer.py:</strong> Complete training pipeline with AutoTokenizer</li>
                    <li><strong>inference.py:</strong> Full inference with chat interface and story generation</li>
                    <li><strong>quick_inference.py:</strong> Fast testing script for model validation</li>
                </ul>
            </div>
            
            <div class="concept-card">
                <h3>🚀 Usage Examples</h3>
                
                <h4>Training a Model:</h4>
                <div class="code-block">
                    <pre><span class="comment"># Download and prepare data</span>
python tiny_stories.py

<span class="comment"># Train the model</span>
python train_with_autotokenizer.py

<span class="comment"># Expected output: Model saved to checkpoints/best_model.pth</span></pre>
                </div>
                
                <h4>Quick Testing:</h4>
                <div class="code-block">
                    <pre><span class="comment"># Test your trained model quickly</span>
python quick_inference.py

<span class="comment"># Output: 3 sample story generations</span></pre>
                </div>
                
                <h4>Interactive Chat:</h4>
                <div class="code-block">
                    <pre><span class="comment"># Full inference with chat interface</span>
python inference.py

<span class="comment"># Choose from:</span>
<span class="comment"># 1. Interactive chat</span>
<span class="comment"># 2. Story generation samples</span>
<span class="comment"># 3. Single prompt</span></pre>
                </div>
            </div>
            
            <div class="learning-tip">
                <strong>💡 Benefits of This Structure:</strong>
                <ul>
                    <li><strong>Separation of Concerns:</strong> Training vs inference logic separated</li>
                    <li><strong>Reusability:</strong> Model classes can be imported by different scripts</li>
                    <li><strong>Testing:</strong> Quick validation separate from full inference</li>
                    <li><strong>Production Ready:</strong> Easy to deploy individual components</li>
                </ul>
            </div>
        </div>
        
        <!-- Summary Section -->
        <div class="section">
            <h2>🎉 Congratulations!</h2>
            <p>
                You've built a working Qwen3 model from scratch! Here's what you've learned:
            </p>
            
            <div class="concept-card">
                <h3>✅ Key Takeaways</h3>
                <ul>
                    <li><strong>GQA:</strong> Saves memory by sharing K,V heads (up to 16:1 ratio in Qwen3-235B)</li>
                    <li><strong>RoPE:</strong> Encodes positions through rotation, extended to 128K context with YARN</li>
                    <li><strong>QK Normalization:</strong> New in Qwen3 for training stability</li>
                    <li><strong>Thinking Modes:</strong> Can switch between fast and deep reasoning</li>
                    <li><strong>Architecture:</strong> RMSNorm, SwiGLU, no QKV bias</li>
                </ul>
            </div>
            
            <div class="concept-card">
                <h3>✅ Production Training - UPDATED!</h3>
                <p>Based on real debugging sessions, here's the production-ready training setup:</p>
                
                <div style="margin: 15px 0; padding: 15px; background: #1a4b3a; border-radius: 8px; border: 2px solid #28a745;">
                    <strong>🎯 Ready-to-Use Training Script:</strong>
                    <p>Save this as <code>train_production.py</code> and run with <code>python train_production.py</code></p>
                    
                    <div style="margin: 10px 0;">
                        <strong>Key Fixes Applied:</strong>
                        <ul>
                            <li>✅ <strong>AutoTokenizer:</strong> Real Qwen3 tokenizer (151k vocab)</li>
                            <li>✅ <strong>Token Clamping:</strong> Prevents IndexError crashes</li>
                            <li>✅ <strong>num_workers=0:</strong> Fixes multiprocessing issues</li>
                            <li>✅ <strong>Optimized Config:</strong> 43M params for MacBook Air</li>
                            <li>✅ <strong>Fast Training:</strong> 1 epoch + higher learning rate</li>
                        </ul>
                    </div>
                </div>
                
                <div class="code-block" style="max-height: 600px; overflow-y: auto;">
                    <button class="copy-button" onclick="copyCode('final-training-script')">Copy Full Script</button>
                    <pre id="final-training-script" style="font-size: 11px;"><span class="comment">#!/usr/bin/env python3</span>
<span class="keyword">import</span> os, json, glob, torch, torch.optim <span class="keyword">as</span> optim
<span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader
<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm
<span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer
<span class="keyword">from</span> nano_qwen3 <span class="keyword">import</span> Qwen3Config, Qwen3ForCausalLM

os.environ[<span class="string">"TOKENIZERS_PARALLELISM"</span>] = <span class="string">"false"</span>

<span class="keyword">class</span> <span class="class-name">TinyStoriesDataset</span>(Dataset):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, data_dir, tokenizer, max_length=<span class="number">256</span>, split=<span class="string">'train'</span>):
        self.tokenizer, self.max_length, self.stories = tokenizer, max_length, []
        json_pattern = os.path.join(data_dir, <span class="string">"tinystories/TinyStories_all_data/*.json"</span>)
        json_files = glob.glob(json_pattern)
        
        json_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> json_files <span class="keyword">if</span> (<span class="string">'data00.json'</span> <span class="keyword">not in</span> f) <span class="keyword">if</span> split == <span class="string">'train'</span> <span class="keyword">else</span> (<span class="string">'data00.json'</span> <span class="keyword">in</span> f)]
        
        <span class="keyword">for</span> json_file <span class="keyword">in</span> tqdm(json_files[:<span class="number">2</span>], desc=<span class="string">f"Loading {split}"</span>):
            <span class="keyword">with</span> open(json_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:
                <span class="keyword">for</span> item <span class="keyword">in</span> json.load(f):
                    <span class="keyword">if</span> isinstance(item, dict) <span class="keyword">and</span> <span class="string">'story'</span> <span class="keyword">in</span> item <span class="keyword">and</span> len(item[<span class="string">'story'</span>].strip()) > <span class="number">10</span>:
                        self.stories.append(item[<span class="string">'story'</span>].strip())
    
    <span class="keyword">def</span> <span class="function">__len__</span>(self): <span class="keyword">return</span> len(self.stories)
    
    <span class="keyword">def</span> <span class="function">__getitem__</span>(self, idx):
        encoding = self.tokenizer(self.stories[idx], max_length=self.max_length,
                                padding=<span class="string">'max_length'</span>, truncation=<span class="keyword">True</span>, return_tensors=<span class="string">'pt'</span>)
        input_ids = encoding[<span class="string">'input_ids'</span>].squeeze(<span class="number">0</span>)
        <span class="keyword">return</span> torch.clamp(input_ids, <span class="number">0</span>, self.tokenizer.vocab_size - <span class="number">1</span>)

<span class="keyword">def</span> <span class="function">train_production</span>():
    device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)
    
    <span class="comment"># Load Qwen3 tokenizer</span>
    tokenizer = AutoTokenizer.from_pretrained(<span class="string">"Qwen/Qwen3-8B"</span>)
    <span class="keyword">if</span> tokenizer.pad_token <span class="keyword">is</span> <span class="keyword">None</span>: tokenizer.pad_token = tokenizer.eos_token
    
    <span class="comment"># MacBook Air optimized config</span>
    config = Qwen3Config()
    config.hidden_size, config.num_hidden_layers = <span class="number">256</span>, <span class="number">4</span>
    config.num_attention_heads, config.num_key_value_heads = <span class="number">8</span>, <span class="number">4</span>
    config.intermediate_size, config.max_position_embeddings = <span class="number">1024</span>, <span class="number">256</span>
    config.vocab_size = tokenizer.vocab_size
    
    <span class="comment"># Create dataset and model</span>
    dataset = TinyStoriesDataset(<span class="string">"."</span>, tokenizer, config.max_position_embeddings)
    dataloader = DataLoader(dataset, batch_size=<span class="number">8</span>, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">0</span>)
    model = Qwen3ForCausalLM(config).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=<span class="number">2e-4</span>, weight_decay=<span class="number">0.01</span>)
    
    print(<span class="string">f"Training {sum(p.numel() for p in model.parameters()):,} parameters on {len(dataset)} stories"</span>)
    
    <span class="comment"># Training loop</span>
    model.train()
    <span class="keyword">for</span> step, input_ids <span class="keyword">in</span> enumerate(tqdm(dataloader, desc=<span class="string">"Training"</span>)):
        input_ids = input_ids.to(device)
        logits, loss = model(input_ids, labels=input_ids.clone())
        
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)
        optimizer.step()
        
        <span class="keyword">if</span> step % <span class="number">50</span> == <span class="number">0</span>:
            print(<span class="string">f"Step {step}, Loss: {loss.item():.4f}"</span>)
    
    <span class="comment"># Save model</span>
    os.makedirs(<span class="string">"checkpoints"</span>, exist_ok=<span class="keyword">True</span>)
    torch.save({<span class="string">'model_state_dict'</span>: model.state_dict(), <span class="string">'config'</span>: config, 
               <span class="string">'tokenizer_name'</span>: <span class="string">"Qwen/Qwen3-8B"</span>}, <span class="string">"checkpoints/final_model.pth"</span>)
    print(<span class="string">"✅ Training complete! Model saved to checkpoints/final_model.pth"</span>)

<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>: train_production()</pre>
                </div>
                
                <div style="margin: 15px 0; padding: 15px; background: #2a2a2a; border-radius: 8px;">
                    <strong>📊 Expected Results:</strong>
                    <ul>
                        <li><strong>Training Time:</strong> ~15-30 minutes (reduced dataset)</li>
                        <li><strong>Starting Loss:</strong> ~21 (due to large vocabulary)</li>
                        <li><strong>Target Loss:</strong> ~6-8 for readable stories</li>
                        <li><strong>Memory Usage:</strong> ~2-3GB RAM</li>
                        <li><strong>Model Size:</strong> 43M parameters (~163MB)</li>
                    </ul>
                </div>
            </div>
            
            <div class="concept-card">
                <h3>🧪 Test Your Trained Model</h3>
                <p>After training, test story generation with this script:</p>
                
                <div class="code-block">
                    <button class="copy-button" onclick="copyCode('test-script')">Copy Test Script</button>
                    <pre id="test-script"><span class="comment">#!/usr/bin/env python3</span>
<span class="keyword">import</span> torch
<span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer
<span class="keyword">from</span> nano_qwen3 <span class="keyword">import</span> Qwen3ForCausalLM

<span class="keyword">def</span> <span class="function">test_stories</span>():
    <span class="comment"># Load trained model</span>
    checkpoint = torch.load(<span class="string">"checkpoints/final_model.pth"</span>, map_location=<span class="string">'cpu'</span>)
    model = Qwen3ForCausalLM(checkpoint[<span class="string">'config'</span>])
    model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])
    model.eval()
    
    tokenizer = AutoTokenizer.from_pretrained(<span class="string">"Qwen/Qwen3-8B"</span>)
    <span class="keyword">if</span> tokenizer.pad_token <span class="keyword">is</span> <span class="keyword">None</span>: tokenizer.pad_token = tokenizer.eos_token
    
    <span class="comment"># Test story generation</span>
    prompts = [<span class="string">"Once upon a time"</span>, <span class="string">"The little girl"</span>, <span class="string">"In a magical forest"</span>]
    
    <span class="keyword">for</span> prompt <span class="keyword">in</span> prompts:
        inputs = tokenizer(prompt, return_tensors=<span class="string">'pt'</span>)
        <span class="keyword">with</span> torch.no_grad():
            generated = model.generate(inputs[<span class="string">'input_ids'</span>], max_length=<span class="number">80</span>, temperature=<span class="number">0.8</span>)
            story = tokenizer.decode(generated[<span class="number">0</span>], skip_special_tokens=<span class="keyword">True</span>)
        print(<span class="string">f"Prompt: {prompt}"</span>)
        print(<span class="string">f"Story: {story}\n"</span>)

<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>: test_stories()</pre>
                </div>
            </div>
            
            <div class="concept-card">
                <h3>🚀 Advanced Challenges</h3>
                <p>Ready to go deeper? Try these advanced implementations:</p>
                
                <div style="margin: 15px 0;">
                    <strong>🎯 Level 1: Improvements</strong>
                    <ul>
                        <li><strong>Longer Training:</strong> Remove dataset limits and train on full TinyStories</li>
                        <li><strong>Better Evaluation:</strong> Add validation loss and perplexity tracking</li>
                        <li><strong>Learning Rate Scheduling:</strong> Implement cosine annealing or warm-up</li>
                    </ul>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>🎯 Level 2: Features</strong>
                    <ul>
                        <li><strong>Thinking Mode:</strong> Add &lt;think&gt; tokens and reasoning chains</li>
                        <li><strong>Long Context:</strong> Implement YARN scaling for 32K+ context</li>
                        <li><strong>Inference Optimization:</strong> Add KV caching for faster generation</li>
                    </ul>
                </div>
                
                <div style="margin: 15px 0;">
                    <strong>🎯 Level 3: Research</strong>
                    <ul>
                        <li><strong>New Attention:</strong> Try different GQA ratios (8:1, 16:1)</li>
                        <li><strong>Architecture Ablation:</strong> Test with/without QK norm, different activations</li>
                        <li><strong>Scale Up:</strong> Train larger models (50M, 100M parameters)</li>
                    </ul>
                </div>
            </div>
            
            <div class="code-block">
                <button class="copy-button" onclick="copyCode('complete-example')">Copy</button>
                <pre id="complete-example"># Complete working example to get you started!
import torch
import torch.nn as nn

# Use all the code from the challenges above, then:

def quick_test():
    """Test your Qwen3 implementation"""
    config = Qwen3Config()
    model = Qwen3ForCausalLM(config)
    
    # Generate some text
    input_ids = torch.randint(0, config.vocab_size, (1, 5))
    output = model.generate(input_ids, max_length=20)
    
    print(f"Input tokens: {input_ids}")
    print(f"Generated tokens: {output}")
    print("🎉 Your Qwen3 model is working!")

if __name__ == "__main__":
    quick_test()</pre>
            </div>
            
            <div class="learning-tip">
                <strong>📚 Additional Resources:</strong>
                <ul>
                    <li><strong>Qwen3 Paper:</strong> Official technical report with all implementation details</li>
                    <li><strong>Attention is All You Need:</strong> Original transformer paper</li>
                    <li><strong>TinyStories Dataset:</strong> Perfect for testing small language models</li>
                    <li><strong>nanoGPT:</strong> Karpathy's minimal GPT implementation for reference</li>
                </ul>
            </div>
            
            <div class="concept-card">
                <h3>📚 References from the Paper</h3>
                <ul>
                    <li>Qwen3 uses GQA with ratios from 2:1 to 16:1</li>
                    <li>Training on 36 trillion tokens across 119 languages</li>
                    <li>Thinking mode uses chain-of-thought and reinforcement learning</li>
                    <li>Even Qwen3-0.6B outperforms much larger older models</li>
                    <li>The paper shows detailed benchmarks and comparisons</li>
                </ul>
            </div>
        </div>
    </div>
</body>
</html>